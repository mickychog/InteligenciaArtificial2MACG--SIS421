{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mecanismos de Atención"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "import unicodedata\n",
    "import re\n",
    "import random\n",
    "import torch\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.ticker as ticker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import unicodedata\n",
    "import re\n",
    "\n",
    "def unicodeToAscii(s): #transforma letras especiales en normales\n",
    "    return ''.join(\n",
    "        c for c in unicodedata.normalize('NFD', s)\n",
    "        if unicodedata.category(c) != 'Mn'\n",
    "    )\n",
    "\n",
    "def normalizeString(s):\n",
    "    s = unicodeToAscii(s.lower().strip()) # elimina espacio en blanco y lo vuelve minuscula\n",
    "    s = re.sub(r\"([.!?])\", r\" \\1\", s)\n",
    "    s = re.sub(r\"[^a-zA-Z.!?]+\", r\" \", s) #transforma un caracter que no es ingles a un espacio en blanco\n",
    "    return s\n",
    "\n",
    "def read_file(file, reverse=False):\n",
    "    # Leer el archivo y dividirlo en líneas\n",
    "    lines = open(file, encoding='utf-8').read().strip().split('\\n')\n",
    "\n",
    "    # Dividir cada línea en pares y normalizar\n",
    "    pairs = [[normalizeString(s) for s in l.split('\\t')[:2]] for l in lines]\n",
    "\n",
    "    return pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "pairs = read_file('eng-fra.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['i won t forget .', 'je n oublierai pas .']"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import random\n",
    "random.choice(pairs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "SOS_token = 0\n",
    "EOS_token = 1\n",
    "PAD_token = 2\n",
    "\n",
    "class Lang:\n",
    "    def __init__(self, name):\n",
    "        self.name = name\n",
    "        self.word2index = {\"SOS\": 0, \"EOS\": 1, \"PAD\": 2, \"UNK\": 3}\n",
    "        self.word2count = {}\n",
    "        self.index2word = {0: \"SOS\", 1: \"EOS\", 2: \"PAD\", 3: \"UNK\"}\n",
    "        self.n_words = 4  # Count SOS, EOS, PAD, and UNK\n",
    "\n",
    "    def addSentence(self, sentence):\n",
    "        for word in sentence.split(' '):\n",
    "            self.addWord(word)\n",
    "\n",
    "    def addWord(self, word):\n",
    "        if word not in self.word2index:\n",
    "            self.word2index[word] = self.n_words\n",
    "            self.word2count[word] = 1\n",
    "            self.index2word[self.n_words] = word\n",
    "            self.n_words += 1\n",
    "        else:\n",
    "            self.word2count[word] += 1\n",
    "\n",
    "    def indexesFromSentence(self, sentence):\n",
    "        return [self.word2index.get(word, self.word2index[\"UNK\"]) for word in sentence.split(' ')]\n",
    "\n",
    "    def sentenceFromIndex(self, index):\n",
    "        return [self.index2word[ix] for ix in index]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_LENGTH = 10\n",
    "\n",
    "def filterPairs(pairs, filters, lang=0):\n",
    "    return [p for p in pairs if p[lang].startswith(filters)]\n",
    "\n",
    "def trimPairs(pairs):\n",
    "    return [p for p in pairs if len(p[0].split(' ')) < MAX_LENGTH and len(p[1].split(' ')) < MAX_LENGTH]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tenemos 135842 pares de frases\n",
      "Tenemos 95170 pares de frases con longitud menor de 10\n",
      "Longitud vocabularios:\n",
      "eng 10027\n",
      "fra 16815\n",
      "['there was little sugar left in the pot .', 'il restait peu de sucre dans le bocal .']\n"
     ]
    }
   ],
   "source": [
    "def prepareData(file, filters=None, reverse=False):\n",
    "\n",
    "    pairs = read_file(file, reverse)\n",
    "    print(f\"Tenemos {len(pairs)} pares de frases\")\n",
    "\n",
    "    if filters is not None:\n",
    "        pairs = filterPairs(pairs, filters, int(reverse))\n",
    "        print(f\"Filtramos a {len(pairs)} pares de frases\")\n",
    "\n",
    "    pairs = trimPairs(pairs)\n",
    "    print(f\"Tenemos {len(pairs)} pares de frases con longitud menor de {MAX_LENGTH}\")\n",
    "\n",
    "    # Reverse pairs, make Lang instances\n",
    "    if reverse:\n",
    "        pairs = [list(reversed(p)) for p in pairs]\n",
    "        input_lang = Lang('fra')\n",
    "        output_lang = Lang('eng')\n",
    "    else:\n",
    "        input_lang = Lang('eng')\n",
    "        output_lang = Lang('fra')\n",
    "\n",
    "    for pair in pairs:\n",
    "        input_lang.addSentence(pair[0])\n",
    "        output_lang.addSentence(pair[1])\n",
    "\n",
    "    # Print vocabulary lengths\n",
    "    print(\"Longitud vocabularios:\")\n",
    "    print(input_lang.name, input_lang.n_words)\n",
    "    print(output_lang.name, output_lang.n_words)\n",
    "\n",
    "    return input_lang, output_lang, pairs\n",
    "\n",
    "# Use the updated function to prepare data for English-French translation\n",
    "input_lang, output_lang, pairs = prepareData('eng-fra.txt')\n",
    "\n",
    "# Print a random pair to verify\n",
    "print(random.choice(pairs))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[10628, 3, 3, 3, 16]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_lang.indexesFromSentence('the day is beautiful.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['jubilez', 'loucha', 'serieuse', '.']"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_lang.sentenceFromIndex([1000, 1028, 647, 16])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(76136, 19034)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "class Dataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, input_lang, output_lang, pairs, max_length):\n",
    "        self.input_lang = input_lang\n",
    "        self.output_lang = output_lang\n",
    "        self.pairs = pairs\n",
    "        self.max_length = max_length\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.pairs)\n",
    "\n",
    "    def __getitem__(self, ix):\n",
    "        inputs = torch.tensor(self.input_lang.indexesFromSentence(self.pairs[ix][0]), device=device, dtype=torch.long)\n",
    "        outputs = torch.tensor(self.output_lang.indexesFromSentence(self.pairs[ix][1]), device=device, dtype=torch.long)\n",
    "        # metemos padding a todas las frases hast a la longitud máxima\n",
    "        return torch.nn.functional.pad(inputs, (0, self.max_length - len(inputs)), 'constant', self.input_lang.word2index['PAD']), \\\n",
    "            torch.nn.functional.pad(outputs, (0, self.max_length - len(outputs)), 'constant', self.output_lang.word2index['PAD'])\n",
    "\n",
    "# separamos datos en train-test\n",
    "train_size = len(pairs) * 80 // 100\n",
    "train = pairs[:train_size]\n",
    "test = pairs[train_size:]\n",
    "\n",
    "dataset = {\n",
    "    'train': Dataset(input_lang, output_lang, train, max_length=MAX_LENGTH),\n",
    "    'test': Dataset(input_lang, output_lang, test, max_length=MAX_LENGTH)\n",
    "}\n",
    "\n",
    "len(dataset['train']), len(dataset['test'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([6, 7, 2, 2, 2, 2, 2, 2, 2, 2], device='cuda:0'),\n",
       " tensor([6, 5, 2, 2, 2, 2, 2, 2, 2, 2], device='cuda:0'))"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_sentence, output_sentence = dataset['train'][1]\n",
    "\n",
    "input_sentence, output_sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['run', '!', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD'],\n",
       " ['cours', '!', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD'])"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_lang.sentenceFromIndex(input_sentence.tolist()), output_lang.sentenceFromIndex(output_sentence.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([64, 10]), torch.Size([64, 10]))"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataloader = {\n",
    "    'train': torch.utils.data.DataLoader(dataset['train'], batch_size=64, shuffle=True),\n",
    "    'test': torch.utils.data.DataLoader(dataset['test'], batch_size=256, shuffle=False),\n",
    "}\n",
    "\n",
    "inputs, outputs = next(iter(dataloader['train']))\n",
    "inputs.shape, outputs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(torch.nn.Module):\n",
    "    def __init__(self, input_size, embedding_size=100, hidden_size=100, n_layers=2):\n",
    "        super().__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.embedding = torch.nn.Embedding(input_size, embedding_size)\n",
    "        self.gru = torch.nn.GRU(embedding_size, hidden_size, num_layers=n_layers, batch_first=True)\n",
    "\n",
    "    def forward(self, input_sentences):\n",
    "        embedded = self.embedding(input_sentences)\n",
    "        outputs, hidden = self.gru(embedded)\n",
    "        return outputs, hidden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([64, 10, 100])"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoder = Encoder(input_size=input_lang.n_words)\n",
    "encoder_outputs, encoder_hidden = encoder(torch.randint(0, input_lang.n_words, (64, 10)))\n",
    "\n",
    "# [batch size, seq len, hidden size] \n",
    "encoder_outputs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 64, 100])"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# [num layers, batch size, hidden size]\n",
    "encoder_hidden.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AttnDecoder(torch.nn.Module):\n",
    "    def __init__(self, input_size, embedding_size=100, hidden_size=100, n_layers=2, max_length=MAX_LENGTH):\n",
    "        super().__init__()\n",
    "\n",
    "        self.embedding = torch.nn.Embedding(input_size, embedding_size)\n",
    "        self.gru = torch.nn.GRU(embedding_size, hidden_size, num_layers=n_layers, batch_first=True)\n",
    "        self.out = torch.nn.Linear(hidden_size, input_size)\n",
    "\n",
    "        # attention\n",
    "        self.attn = torch.nn.Linear(hidden_size + embedding_size, max_length)\n",
    "        self.attn_combine = torch.nn.Linear(hidden_size * 2, hidden_size)\n",
    "\n",
    "\n",
    "    def forward(self, input_words, hidden, encoder_outputs):\n",
    "        # sacamos los embeddings\n",
    "        embedded = self.embedding(input_words)\n",
    "        # calculamos los pesos de la capa de atención\n",
    "        attn_weights = torch.nn.functional.softmax(self.attn(torch.cat((embedded.squeeze(1), hidden[0]), dim=1)))\n",
    "        # re-escalamos los outputs del encoder con estos pesos\n",
    "        attn_applied = torch.bmm(attn_weights.unsqueeze(1), encoder_outputs)\n",
    "        output = torch.cat((embedded.squeeze(1), attn_applied.squeeze(1)), 1)\n",
    "        # aplicamos la capa de atención\n",
    "        output = self.attn_combine(output)\n",
    "        output = torch.nn.functional.relu(output)\n",
    "        # a partir de aquí, como siempre. La diferencia es que la entrada a la RNN\n",
    "        # no es directmanete el embedding sino una combinación del embedding\n",
    "        # y las salidas del encoder re-escaladas\n",
    "        output, hidden = self.gru(output.unsqueeze(1), hidden)\n",
    "        output = self.out(output.squeeze(1))\n",
    "        return output, hidden, attn_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\micky\\AppData\\Local\\Temp\\ipykernel_4900\\1629649894.py:18: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  attn_weights = torch.nn.functional.softmax(self.attn(torch.cat((embedded.squeeze(1), hidden[0]), dim=1)))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([64, 16815])"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decoder = AttnDecoder(input_size=output_lang.n_words)\n",
    "decoder_output, decoder_hidden, attn_weights = decoder(torch.randint(0, output_lang.n_words, (64, 1)), encoder_hidden, encoder_outputs)\n",
    "\n",
    "# [batch size, vocab size]\n",
    "decoder_output.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 64, 100])"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# [num layers, batch size, hidden size]\n",
    "decoder_hidden.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([64, 10])"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# [batch size, max_length]\n",
    "attn_weights.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Entrenamiento"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamos a implementar el bucle de entrenamiento. En primer lugar, al tener ahora dos redes neuronales, necesitaremos dos optimizadores (uno para el `encoder` y otro para el `decoder`). Al `encoder` le pasaremos la frase en el idioma original, y obtendremos el estado oculto final. Este estado oculto lo usaremos para inicializar el `decoder` que, junto al token `<sos>`, generará la primera palabra de la frase traducida. Repetiremos el proceso, utilizando como entrada la anterior salida del decoder, hasta obtener el token `<eos>`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import torch\n",
    "import zipfile\n",
    "import os\n",
    "\n",
    "def fit(encoder, decoder, dataloader, epochs=10):\n",
    "    encoder.to(device)\n",
    "    decoder.to(device)\n",
    "    encoder_optimizer = torch.optim.Adam(encoder.parameters(), lr=1e-3)\n",
    "    decoder_optimizer = torch.optim.Adam(decoder.parameters(), lr=1e-3)\n",
    "    criterion = torch.nn.CrossEntropyLoss()\n",
    "    for epoch in range(1, epochs+1):\n",
    "        encoder.train()\n",
    "        decoder.train()\n",
    "        train_loss = []\n",
    "        bar = tqdm(dataloader['train'])\n",
    "        for batch in bar:\n",
    "            input_sentences, output_sentences = batch\n",
    "            bs = input_sentences.shape[0]\n",
    "            loss = 0\n",
    "            encoder_optimizer.zero_grad()\n",
    "            decoder_optimizer.zero_grad()\n",
    "            # obtenemos el último estado oculto del encoder\n",
    "            encoder_outputs, hidden = encoder(input_sentences)\n",
    "            # calculamos las salidas del decoder de manera recurrente\n",
    "            decoder_input = torch.tensor([[output_lang.word2index['SOS']] for b in range(bs)], device=device)\n",
    "            for i in range(output_sentences.shape[1]):\n",
    "                output, hidden, attn_weights = decoder(decoder_input, hidden, encoder_outputs)\n",
    "                loss += criterion(output, output_sentences[:, i].view(bs))\n",
    "                # el siguiente input será la palabra predicha\n",
    "                decoder_input = torch.argmax(output, axis=1).view(bs, 1)\n",
    "            # optimización\n",
    "            loss.backward()\n",
    "            encoder_optimizer.step()\n",
    "            decoder_optimizer.step()\n",
    "            train_loss.append(loss.item())\n",
    "            bar.set_description(f\"Epoch {epoch}/{epochs} loss {np.mean(train_loss):.5f}\")\n",
    "\n",
    "        val_loss = []\n",
    "        encoder.eval()\n",
    "        decoder.eval()\n",
    "        with torch.no_grad():\n",
    "            bar = tqdm(dataloader['test'])\n",
    "            for batch in bar:\n",
    "                input_sentences, output_sentences = batch\n",
    "                bs = input_sentences.shape[0]\n",
    "                loss = 0\n",
    "                # obtenemos el último estado oculto del encoder\n",
    "                encoder_outputs, hidden = encoder(input_sentences)\n",
    "                # calculamos las salidas del decoder de manera recurrente\n",
    "                decoder_input = torch.tensor([[output_lang.word2index['SOS']] for b in range(bs)], device=device)\n",
    "                for i in range(output_sentences.shape[1]):\n",
    "                    output, hidden, attn_weights = decoder(decoder_input, hidden, encoder_outputs)\n",
    "                    loss += criterion(output, output_sentences[:, i].view(bs))\n",
    "                    # el siguiente input será la palabra predicha\n",
    "                    decoder_input = torch.argmax(output, axis=1).view(bs, 1)\n",
    "                val_loss.append(loss.item())\n",
    "                bar.set_description(f\"Epoch {epoch}/{epochs} val_loss {np.mean(val_loss):.5f}\")\n",
    "                     # Guardamos los pesos entrenados del encoder y decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1190 [00:00<?, ?it/s]C:\\Users\\micky\\AppData\\Local\\Temp\\ipykernel_4900\\1629649894.py:18: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  attn_weights = torch.nn.functional.softmax(self.attn(torch.cat((embedded.squeeze(1), hidden[0]), dim=1)))\n",
      "Epoch 1/30 loss 35.30443: 100%|██████████| 1190/1190 [02:12<00:00,  8.95it/s]\n",
      "Epoch 1/30 val_loss 44.58406: 100%|██████████| 75/75 [00:13<00:00,  5.47it/s]\n",
      "Epoch 2/30 loss 27.70692: 100%|██████████| 1190/1190 [02:14<00:00,  8.82it/s]\n",
      "Epoch 2/30 val_loss 41.93332: 100%|██████████| 75/75 [00:13<00:00,  5.54it/s]\n",
      "Epoch 3/30 loss 24.42390: 100%|██████████| 1190/1190 [02:03<00:00,  9.64it/s]\n",
      "Epoch 3/30 val_loss 39.44054: 100%|██████████| 75/75 [00:13<00:00,  5.75it/s]\n",
      "Epoch 4/30 loss 22.07962: 100%|██████████| 1190/1190 [02:11<00:00,  9.03it/s]\n",
      "Epoch 4/30 val_loss 38.38985: 100%|██████████| 75/75 [00:13<00:00,  5.57it/s]\n",
      "Epoch 5/30 loss 20.25973: 100%|██████████| 1190/1190 [02:03<00:00,  9.64it/s]\n",
      "Epoch 5/30 val_loss 37.91477: 100%|██████████| 75/75 [00:13<00:00,  5.75it/s]\n",
      "Epoch 6/30 loss 18.77694: 100%|██████████| 1190/1190 [01:59<00:00,  9.96it/s]\n",
      "Epoch 6/30 val_loss 37.40228: 100%|██████████| 75/75 [00:12<00:00,  6.20it/s]\n",
      "Epoch 7/30 loss 17.52289: 100%|██████████| 1190/1190 [01:59<00:00,  9.98it/s]\n",
      "Epoch 7/30 val_loss 37.40902: 100%|██████████| 75/75 [00:12<00:00,  5.90it/s]\n",
      "Epoch 8/30 loss 16.42827: 100%|██████████| 1190/1190 [02:09<00:00,  9.16it/s]\n",
      "Epoch 8/30 val_loss 37.46049: 100%|██████████| 75/75 [00:12<00:00,  6.06it/s]\n",
      "Epoch 9/30 loss 15.47617: 100%|██████████| 1190/1190 [02:06<00:00,  9.39it/s]\n",
      "Epoch 9/30 val_loss 37.60829: 100%|██████████| 75/75 [00:13<00:00,  5.62it/s]\n",
      "Epoch 10/30 loss 14.64661: 100%|██████████| 1190/1190 [02:11<00:00,  9.04it/s]\n",
      "Epoch 10/30 val_loss 37.52388: 100%|██████████| 75/75 [00:13<00:00,  5.61it/s]\n",
      "Epoch 11/30 loss 13.92238: 100%|██████████| 1190/1190 [01:30<00:00, 13.19it/s]\n",
      "Epoch 11/30 val_loss 37.60558: 100%|██████████| 75/75 [00:13<00:00,  5.58it/s]\n",
      "Epoch 12/30 loss 13.26885: 100%|██████████| 1190/1190 [02:18<00:00,  8.57it/s]\n",
      "Epoch 12/30 val_loss 38.02480: 100%|██████████| 75/75 [00:13<00:00,  5.40it/s]\n",
      "Epoch 13/30 loss 12.71167: 100%|██████████| 1190/1190 [02:22<00:00,  8.33it/s]\n",
      "Epoch 13/30 val_loss 38.28715: 100%|██████████| 75/75 [00:14<00:00,  5.29it/s]\n",
      "Epoch 14/30 loss 12.20061: 100%|██████████| 1190/1190 [02:16<00:00,  8.71it/s]\n",
      "Epoch 14/30 val_loss 38.89070: 100%|██████████| 75/75 [00:14<00:00,  5.24it/s]\n",
      "Epoch 15/30 loss 11.74113: 100%|██████████| 1190/1190 [02:01<00:00,  9.82it/s]\n",
      "Epoch 15/30 val_loss 39.20865: 100%|██████████| 75/75 [00:05<00:00, 13.68it/s]\n",
      "Epoch 16/30 loss 11.34703: 100%|██████████| 1190/1190 [01:58<00:00, 10.00it/s]\n",
      "Epoch 16/30 val_loss 39.66847: 100%|██████████| 75/75 [00:13<00:00,  5.48it/s]\n",
      "Epoch 17/30 loss 10.98962: 100%|██████████| 1190/1190 [02:19<00:00,  8.51it/s]\n",
      "Epoch 17/30 val_loss 39.72963: 100%|██████████| 75/75 [00:14<00:00,  5.26it/s]\n",
      "Epoch 18/30 loss 10.64386: 100%|██████████| 1190/1190 [02:18<00:00,  8.57it/s]\n",
      "Epoch 18/30 val_loss 40.29285: 100%|██████████| 75/75 [00:13<00:00,  5.39it/s]\n",
      "Epoch 19/30 loss 10.33970: 100%|██████████| 1190/1190 [02:17<00:00,  8.68it/s]\n",
      "Epoch 19/30 val_loss 40.60287: 100%|██████████| 75/75 [00:13<00:00,  5.46it/s]\n",
      "Epoch 20/30 loss 10.07399: 100%|██████████| 1190/1190 [02:10<00:00,  9.09it/s]\n",
      "Epoch 20/30 val_loss 40.89346: 100%|██████████| 75/75 [00:13<00:00,  5.37it/s]\n",
      "Epoch 21/30 loss 9.83025: 100%|██████████| 1190/1190 [02:12<00:00,  8.95it/s]\n",
      "Epoch 21/30 val_loss 41.05080: 100%|██████████| 75/75 [00:14<00:00,  5.11it/s]\n",
      "Epoch 22/30 loss 9.57190: 100%|██████████| 1190/1190 [02:16<00:00,  8.73it/s]\n",
      "Epoch 22/30 val_loss 41.29952: 100%|██████████| 75/75 [00:13<00:00,  5.48it/s]\n",
      "Epoch 23/30 loss 9.38236: 100%|██████████| 1190/1190 [02:35<00:00,  7.64it/s]\n",
      "Epoch 23/30 val_loss 42.02307: 100%|██████████| 75/75 [00:26<00:00,  2.80it/s]\n",
      "Epoch 24/30 loss 9.16501: 100%|██████████| 1190/1190 [02:18<00:00,  8.60it/s]\n",
      "Epoch 24/30 val_loss 42.20387: 100%|██████████| 75/75 [00:04<00:00, 15.07it/s]\n",
      "Epoch 25/30 loss 8.99504: 100%|██████████| 1190/1190 [00:58<00:00, 20.38it/s]\n",
      "Epoch 25/30 val_loss 42.30334: 100%|██████████| 75/75 [00:05<00:00, 14.77it/s]\n",
      "Epoch 26/30 loss 8.81396: 100%|██████████| 1190/1190 [00:58<00:00, 20.23it/s]\n",
      "Epoch 26/30 val_loss 42.53275: 100%|██████████| 75/75 [00:04<00:00, 15.05it/s]\n",
      "Epoch 27/30 loss 8.64922: 100%|██████████| 1190/1190 [00:58<00:00, 20.40it/s]\n",
      "Epoch 27/30 val_loss 37.36921:  56%|█████▌    | 42/75 [00:03<00:02, 13.84it/s]"
     ]
    }
   ],
   "source": [
    "fit(encoder, decoder, dataloader, epochs=30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generando traducciones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_sentence, output_sentence = dataset['train'][5000]\n",
    "input_lang.sentenceFromIndex(input_sentence.tolist()), output_lang.sentenceFromIndex(output_sentence.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(input_sentence):\n",
    "    # obtener el último estado oculto del encoder\n",
    "    encoder_outputs, hidden = encoder(input_sentence.unsqueeze(0))\n",
    "    # calcular las salidas del decoder de manera recurrente\n",
    "    decoder_input = torch.tensor([[output_lang.word2index['SOS']]], device=device)\n",
    "    # iterar hasta que el decoder nos de el token <eos> o hasta que el max length sea alcanzado\n",
    "    outputs = []\n",
    "    decoder_attentions = torch.zeros(MAX_LENGTH, MAX_LENGTH)\n",
    "    i = 0\n",
    "    while True:\n",
    "        output, hidden, attn_weights = decoder(decoder_input, hidden, encoder_outputs)\n",
    "        if i < MAX_LENGTH:\n",
    "            decoder_attentions[i] = attn_weights.data\n",
    "        decoder_input = torch.argmax(output, axis=1).view(1, 1)\n",
    "        outputs.append(decoder_input.cpu().item())\n",
    "        if decoder_input.item() == output_lang.word2index['EOS'] or i >= MAX_LENGTH - 1:\n",
    "            break\n",
    "        i += 1\n",
    "    return output_lang.sentenceFromIndex(outputs), decoder_attentions[:i+1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_words, attn = predict(input_sentence)\n",
    "output_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def showAttention(input_sentence, output_words, attentions):\n",
    "    try:\n",
    "        lim1 = input_sentence.index('EOS') + 1\n",
    "    except ValueError:\n",
    "        lim1 = len(input_sentence)\n",
    "\n",
    "    try:\n",
    "        lim2 = output_words.index('EOS') + 1\n",
    "    except ValueError:\n",
    "        lim2 = len(output_words)\n",
    "\n",
    "    fig = plt.figure(dpi=100)\n",
    "    ax = fig.add_subplot(111)\n",
    "    cax = ax.matshow(attentions[:lim2, :lim1].numpy(), cmap='bone')\n",
    "    fig.colorbar(cax)\n",
    "\n",
    "    # Set up axes\n",
    "    ax.set_xticklabels([' '] + input_sentence[:lim1], rotation=90)\n",
    "    ax.set_yticklabels([' '] + output_words[:lim2])\n",
    "\n",
    "    # Show label at every tick\n",
    "    ax.xaxis.set_major_locator(ticker.MultipleLocator(1))\n",
    "    ax.yaxis.set_major_locator(ticker.MultipleLocator(1))\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "showAttention(input_lang.sentenceFromIndex(input_sentence.tolist()), output_words, attn)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
