{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3250C7AVk641"
      },
      "source": [
        "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/sensioai/blog/blob/master/054_pytorch_save/pytorch_save.ipynb)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wXnmx7U3k644"
      },
      "source": [
        "# Pytorch - Guardando y Exportando Modelos"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fKBuABZuk644"
      },
      "source": [
        "En posts anteriores hemos aprendido a utilizar la librería [Pytorch](https://pytorch.org/), viendo los [conceptos baśicos](https://sensioai.com/blog/027_pytorch_intro), cómo diseñar y entrenar [redes neuroanles](https://sensioai.com/blog/028_pytorch_nn) y a manejar [datasets](https://sensioai.com/blog/029_pytorch_datasets) de manera eficiente. Sin embargo, entrenar un modelo es solo parte del trabajo. Una vez tenemos nuestra red lista necesitamos poder guardarla en un archivo, o exportarla, para luego importarla en nuestras aplicaciones y ponerla a trabajar en un entorno de [producción](https://sensioai.com/blog/052_produccion). En este post vamos a ver las diferentes opciones que `Pytorch` nos ofrece a a la hora de exportar modelos."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4f8eEkPMk645"
      },
      "source": [
        "## Guardando modelos"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QMpaFCORk645"
      },
      "source": [
        "### Guardando los parámetros"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PCiOnGUYk645"
      },
      "source": [
        "La primera opción consiste en guardar sólo los parámetros de la red. Para ello, `Pytorch` nos permite guardar el `state_dict` del modelo, un `dict` de `Python` que contiene una relación directa entre todas las capas con parámetros de la red y sus valores.\n",
        "\n",
        "En el siguiente código, utilizado ya en [este](https://sensioai.com/blog/042_cnns) post, entrenamos un modelo simple con el dataset `MNIST` y, una vez entrenado, guardamos el `state_dict` del modelo."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "-rwJhm2rk646",
        "outputId": "a41d2411-cef9-43ba-bf70-b953b46970b9"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'cuda'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 1
        }
      ],
      "source": [
        "import torch\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "from tqdm import tqdm\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from torch.utils.data import TensorDataset\n",
        "from torch.utils.data import DataLoader, TensorDataset\n",
        "\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "device"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V_ApDNsQYGCZ",
        "outputId": "7723e850-3633-48d5-93d9-ea02ad138928"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9RI-FSbJk647",
        "outputId": "83962a05-6f5d-48b7-cf81-2d5b1203b772"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Forma de X: (10240, 784)\n",
            "Forma de Y: (10240,)\n"
          ]
        }
      ],
      "source": [
        "# preparamos los datos\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "# Cargar datos desde el archivo CSV\n",
        "mnist = pd.read_csv(\"/content/drive/MyDrive/Inteligencia Artificial 2/Datasets/Dig-MNIST.csv\")\n",
        "\n",
        "# Obtener características (píxeles) y etiquetas (números)\n",
        "X = mnist.iloc[:, 1:].values  # Seleccionar todas las columnas excepto la primera como características\n",
        "Y = mnist.iloc[:, 0].values   # Seleccionar la primera columna como etiquetas\n",
        "\n",
        "# Verificar las formas de X e Y\n",
        "print(\"Forma de X:\", X.shape)\n",
        "print(\"Forma de Y:\", Y.shape)\n",
        "\n",
        "x_2 = np.array(X)\n",
        "y_2 = np.array(Y)\n",
        "\n",
        "# normalización y split\n",
        "X_train = x_2[:8000] / 255.\n",
        "X_test = x_2[8000:] / 255.\n",
        "y_train = y_2[:8000].astype(np.int32)\n",
        "y_test = y_2[8000:].astype(np.int32)\n",
        "\n",
        "# Suponiendo que tus datos son imágenes en escala de grises de tamaño 28x28\n",
        "X_train = X_train.reshape(-1, 1, 28, 28)\n",
        "X_test = X_test.reshape(-1, 1, 28, 28)\n",
        "# Convertir a tensores de torch y enviar a GPU si estás utilizando CUDA\n",
        "X_t = torch.from_numpy(X_train).float().cuda()\n",
        "Y_t = torch.from_numpy(y_train).long().cuda()\n",
        "\n",
        "# Crear datasets y dataloaders\n",
        "train_dataset = TensorDataset(X_t, Y_t)\n",
        "test_dataset = TensorDataset(torch.from_numpy(X_test).float().cuda(), torch.from_numpy(y_test).long().cuda())\n",
        "\n",
        "batch_size = 2048\n",
        "\n",
        "# DataLoader para el conjunto de entrenamiento\n",
        "train_loader = DataLoader(\n",
        "    dataset=train_dataset,\n",
        "    batch_size=batch_size,\n",
        "    shuffle=True\n",
        ")\n",
        "\n",
        "# DataLoader para el conjunto de prueba\n",
        "test_loader = DataLoader(\n",
        "    dataset=test_dataset,\n",
        "    batch_size=batch_size,\n",
        "    shuffle=False\n",
        ")\n",
        "\n",
        "# Diccionario de DataLoaders\n",
        "dataloader = {\n",
        "    'train': train_loader,\n",
        "    'test': test_loader\n",
        "}\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "Es23xeO9k647"
      },
      "outputs": [],
      "source": [
        "# definimos el modelo\n",
        "\n",
        "def block(c_in, c_out, k=3, p=1, s=1, pk=2, ps=2):\n",
        "    return torch.nn.Sequential(\n",
        "        torch.nn.Conv2d(c_in, c_out, k, padding=p, stride=s),\n",
        "        torch.nn.ReLU(),\n",
        "        torch.nn.MaxPool2d(pk, stride=ps)\n",
        "    )\n",
        "\n",
        "class CNN(torch.nn.Module):\n",
        "  def __init__(self, n_channels=1, n_outputs=10):\n",
        "    super().__init__()\n",
        "    self.conv1 = block(n_channels, 64)\n",
        "    self.conv2 = block(64, 128)\n",
        "    self.fc = torch.nn.Linear(128*7*7, n_outputs)\n",
        "\n",
        "  def forward(self, x):\n",
        "    x = self.conv1(x)\n",
        "    x = self.conv2(x)\n",
        "    x = x.view(x.shape[0], -1)\n",
        "    x = self.fc(x)\n",
        "    return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "Kl_694yVk648"
      },
      "outputs": [],
      "source": [
        "# entrenamos el modelo\n",
        "\n",
        "def fit(model, dataloader, epochs=5):\n",
        "    model.to(device)\n",
        "    optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
        "    criterion = torch.nn.CrossEntropyLoss()\n",
        "    for epoch in range(1, epochs+1):\n",
        "        model.train()\n",
        "        train_loss, train_acc = [], []\n",
        "        bar = tqdm(dataloader['train'])\n",
        "        for batch in bar:\n",
        "            X, y = batch\n",
        "            X, y = X.to(device), y.to(device)\n",
        "            optimizer.zero_grad()\n",
        "            y_hat = model(X)\n",
        "            loss = criterion(y_hat, y)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            train_loss.append(loss.item())\n",
        "            acc = (y == torch.argmax(y_hat, axis=1)).sum().item() / len(y)\n",
        "            train_acc.append(acc)\n",
        "            bar.set_description(f\"loss {np.mean(train_loss):.5f} acc {np.mean(train_acc):.5f}\")\n",
        "        bar = tqdm(dataloader['test'])\n",
        "        val_loss, val_acc = [], []\n",
        "        model.eval()\n",
        "        with torch.no_grad():\n",
        "            for batch in bar:\n",
        "                X, y = batch\n",
        "                X, y = X.to(device), y.to(device)\n",
        "                y_hat = model(X)\n",
        "                loss = criterion(y_hat, y)\n",
        "                val_loss.append(loss.item())\n",
        "                acc = (y == torch.argmax(y_hat, axis=1)).sum().item() / len(y)\n",
        "                val_acc.append(acc)\n",
        "                bar.set_description(f\"val_loss {np.mean(val_loss):.5f} val_acc {np.mean(val_acc):.5f}\")\n",
        "        print(f\"Epoch {epoch}/{epochs} loss {np.mean(train_loss):.5f} val_loss {np.mean(val_loss):.5f} acc {np.mean(train_acc):.5f} val_acc {np.mean(val_acc):.5f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B3SBPmNFk648",
        "outputId": "b8f5db4c-f424-4bce-c450-e5a5dfe3c151"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "loss 2.08610 acc 0.40627: 100%|██████████| 4/4 [00:01<00:00,  3.89it/s]\n",
            "val_loss 1.57158 val_acc 0.75553: 100%|██████████| 2/2 [00:00<00:00, 24.97it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5 loss 2.08610 val_loss 1.57158 acc 0.40627 val_acc 0.75553\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "loss 1.28931 acc 0.73868: 100%|██████████| 4/4 [00:00<00:00,  8.68it/s]\n",
            "val_loss 0.86986 val_acc 0.74276: 100%|██████████| 2/2 [00:00<00:00, 32.13it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 2/5 loss 1.28931 val_loss 0.86986 acc 0.73868 val_acc 0.74276\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "loss 0.82580 acc 0.75684: 100%|██████████| 4/4 [00:00<00:00,  8.58it/s]\n",
            "val_loss 0.79776 val_acc 0.75382: 100%|██████████| 2/2 [00:00<00:00, 26.45it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 3/5 loss 0.82580 val_loss 0.79776 acc 0.75684 val_acc 0.75382\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "loss 0.74933 acc 0.77606: 100%|██████████| 4/4 [00:00<00:00,  8.33it/s]\n",
            "val_loss 0.69482 val_acc 0.82365: 100%|██████████| 2/2 [00:00<00:00, 34.50it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 4/5 loss 0.74933 val_loss 0.69482 acc 0.77606 val_acc 0.82365\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "loss 0.67304 acc 0.80353: 100%|██████████| 4/4 [00:00<00:00,  6.79it/s]\n",
            "val_loss 0.69946 val_acc 0.82764: 100%|██████████| 2/2 [00:00<00:00, 33.74it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 5/5 loss 0.67304 val_loss 0.69946 acc 0.80353 val_acc 0.82764\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "model = CNN()\n",
        "fit(model, dataloader)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "N0h5rb4Bk648"
      },
      "outputs": [],
      "source": [
        "# guardar modelo\n",
        "\n",
        "PATH = './checkpoint.pt'\n",
        "torch.save(model.state_dict(), PATH)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g1qv3A9Ck648"
      },
      "source": [
        "Ahora podemos cargar nuestro modelo y utilizarlo normalmente"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "iqNqQtWgk649",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "500b1787-35ef-40de-a0c4-2a04c32b18ba"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "CNN(\n",
              "  (conv1): Sequential(\n",
              "    (0): Conv2d(1, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (1): ReLU()\n",
              "    (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "  )\n",
              "  (conv2): Sequential(\n",
              "    (0): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (1): ReLU()\n",
              "    (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "  )\n",
              "  (fc): Linear(in_features=6272, out_features=10, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ],
      "source": [
        "# cargar modelo\n",
        "\n",
        "model.load_state_dict(torch.load(PATH))\n",
        "model.eval()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "sSia7nqrk649"
      },
      "outputs": [],
      "source": [
        "def evaluate(model, dataloader):\n",
        "    model.eval()\n",
        "    model.to(device)\n",
        "    bar = tqdm(dataloader['test'])\n",
        "    acc = []\n",
        "    with torch.no_grad():\n",
        "        for batch in bar:\n",
        "            X, y = batch\n",
        "            X, y = X.to(device), y.to(device)\n",
        "            y_hat = model(X)\n",
        "            acc.append((y == torch.argmax(y_hat, axis=1)).sum().item() / len(y))\n",
        "            bar.set_description(f\"acc {np.mean(acc):.5f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "KonnG1Rzk649",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1ec2d9be-c80b-4da7-c161-e213ccf16a7f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "acc 0.82764: 100%|██████████| 2/2 [00:00<00:00, 32.32it/s]\n"
          ]
        }
      ],
      "source": [
        "evaluate(model, dataloader)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rwuA_SqYk649"
      },
      "source": [
        "Si bien de esta manera podemos guardar y cargar el modelo de manera eficiente, necesitamos tener un modelo instanciado para poder llamar a la función `model.load_state_dict()`. Esto significa que necesitaremos la definición de nuestro modelo allá dónde queramos importarlo (lo cual es poco flexible). Alternativamente, `Pytorch` nos permite guardar el modelo entero, y no solo el `state_dict`, de la siguiente manera."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "iCyL2qx2k649"
      },
      "outputs": [],
      "source": [
        "torch.save(model, 'model.pt')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ILsljMOQk649"
      },
      "source": [
        "Y podemos cargar y evaluar nuestro modelo así"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "JpyQuZZBk649",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e931f147-ec00-47aa-9e6a-4ce277b05af0"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "CNN(\n",
              "  (conv1): Sequential(\n",
              "    (0): Conv2d(1, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (1): ReLU()\n",
              "    (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "  )\n",
              "  (conv2): Sequential(\n",
              "    (0): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (1): ReLU()\n",
              "    (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "  )\n",
              "  (fc): Linear(in_features=6272, out_features=10, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ],
      "source": [
        "model = torch.load('model.pt')\n",
        "model.eval()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "nWNE9yMpk64-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d0161780-bf44-4cd0-e771-aeb75b79ae1b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "acc 0.82764: 100%|██████████| 2/2 [00:00<00:00, 31.96it/s]\n"
          ]
        }
      ],
      "source": [
        "evaluate(model, dataloader)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C-BQZ_4gk64-"
      },
      "source": [
        "Si bien de esta forma no necesitamos que nuestro modelo esté instanciado, seguimos necesitando su definición. Es por este motivo que la opción anterior es la recomendada, ya que es más eficiente (sólo guardamos los pesos) y también más flexible (podemos guardar otra información además del `state_dict` de nuestro modelo). Esta opción es ideal para guardar y cargar modelos durante el entrenamiento del mismo, quizás incluso junto al estado del optimizador, de manera que podemos entrenar modelos a partir de estos `checkpoints` en lugar de empezar de cero cada vez. Otro ejemplo consistiría en guardar el `state_dict` del modelo durante el entrenamiento solo cuando mejore una métrica determinada y cargar el mejor modelo al final del entrenamiento (que no tiene porqué coincidir con el último).\n",
        "\n",
        "> ⚡ Aprende más sobre el guardado de modelos en `Pytorch` [aquí](https://pytorch.org/tutorials/beginner/saving_loading_models.html)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "lcRoU5Qdk64-"
      },
      "outputs": [],
      "source": [
        "def fit(model, dataloader, epochs=5, PATH=\"./checkpoint.pt\"):\n",
        "    model.to(device)\n",
        "    optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
        "    criterion = torch.nn.CrossEntropyLoss()\n",
        "    best_acc = 0\n",
        "    for epoch in range(1, epochs+1):\n",
        "        model.train()\n",
        "        train_loss, train_acc = [], []\n",
        "        bar = tqdm(dataloader['train'])\n",
        "        for batch in bar:\n",
        "            X, y = batch\n",
        "            X, y = X.to(device), y.to(device)\n",
        "            optimizer.zero_grad()\n",
        "            y_hat = model(X)\n",
        "            loss = criterion(y_hat, y)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            train_loss.append(loss.item())\n",
        "            acc = (y == torch.argmax(y_hat, axis=1)).sum().item() / len(y)\n",
        "            train_acc.append(acc)\n",
        "            bar.set_description(f\"loss {np.mean(train_loss):.5f} acc {np.mean(train_acc):.5f}\")\n",
        "        bar = tqdm(dataloader['test'])\n",
        "        val_loss, val_acc = [], []\n",
        "        model.eval()\n",
        "        with torch.no_grad():\n",
        "            for batch in bar:\n",
        "                X, y = batch\n",
        "                X, y = X.to(device), y.to(device)\n",
        "                y_hat = model(X)\n",
        "                loss = criterion(y_hat, y)\n",
        "                val_loss.append(loss.item())\n",
        "                acc = (y == torch.argmax(y_hat, axis=1)).sum().item() / len(y)\n",
        "                val_acc.append(acc)\n",
        "                bar.set_description(f\"val_loss {np.mean(val_loss):.5f} val_acc {np.mean(val_acc):.5f}\")\n",
        "        # guardar modelo si es el mejor\n",
        "        val_acc = np.mean(val_acc)\n",
        "        if val_acc > best_acc:\n",
        "            best_acc = val_acc\n",
        "            torch.save(model.state_dict(), PATH)\n",
        "            print(f\"Best model saved at epoch {epoch} with val_acc {val_acc:.5f}\")\n",
        "        print(f\"Epoch {epoch}/{epochs} loss {np.mean(train_loss):.5f} val_loss {np.mean(val_loss):.5f} acc {np.mean(train_acc):.5f} val_acc {np.mean(val_acc):.5f}\")\n",
        "    # cargar el mejor modelo al final del entrenamiento\n",
        "    model.load_state_dict(torch.load(PATH))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "sbGpvav8k64-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "81992fcf-a1a9-48a2-dfde-a10f29848a68"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "loss 2.12411 acc 0.38167: 100%|██████████| 4/4 [00:00<00:00,  9.00it/s]\n",
            "val_loss 1.67019 val_acc 0.72982: 100%|██████████| 2/2 [00:00<00:00, 30.99it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best model saved at epoch 1 with val_acc 0.72982\n",
            "Epoch 1/5 loss 2.12411 val_loss 1.67019 acc 0.38167 val_acc 0.72982\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "loss 1.40057 acc 0.71723: 100%|██████████| 4/4 [00:00<00:00,  9.32it/s]\n",
            "val_loss 0.89624 val_acc 0.78312: 100%|██████████| 2/2 [00:00<00:00, 34.74it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best model saved at epoch 2 with val_acc 0.78312\n",
            "Epoch 2/5 loss 1.40057 val_loss 0.89624 acc 0.71723 val_acc 0.78312\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "loss 0.87548 acc 0.75247: 100%|██████████| 4/4 [00:00<00:00,  9.27it/s]\n",
            "val_loss 0.74317 val_acc 0.78866: 100%|██████████| 2/2 [00:00<00:00, 35.09it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best model saved at epoch 3 with val_acc 0.78866\n",
            "Epoch 3/5 loss 0.87548 val_loss 0.74317 acc 0.75247 val_acc 0.78866\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "loss 0.75722 acc 0.77787: 100%|██████████| 4/4 [00:00<00:00,  6.77it/s]\n",
            "val_loss 0.73908 val_acc 0.79508: 100%|██████████| 2/2 [00:00<00:00, 34.46it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best model saved at epoch 4 with val_acc 0.79508\n",
            "Epoch 4/5 loss 0.75722 val_loss 0.73908 acc 0.77787 val_acc 0.79508\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "loss 0.70375 acc 0.79948: 100%|██████████| 4/4 [00:00<00:00,  8.98it/s]\n",
            "val_loss 0.69368 val_acc 0.81901: 100%|██████████| 2/2 [00:00<00:00, 36.45it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best model saved at epoch 5 with val_acc 0.81901\n",
            "Epoch 5/5 loss 0.70375 val_loss 0.69368 acc 0.79948 val_acc 0.81901\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "model = CNN()\n",
        "fit(model, dataloader)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "A9ShWe4Ok64_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9b3a9477-b0f7-4310-e644-664168b4cdb7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "acc 0.81901: 100%|██████████| 2/2 [00:00<00:00, 35.28it/s]\n"
          ]
        }
      ],
      "source": [
        "evaluate(model, dataloader)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nek0-lIrk64_"
      },
      "source": [
        "Guardar nuestros modelos, ya sea el modelo entero o solo su `state_dict`, es la forma más directa y sencilla de guardar cualquier modelo que hagamos. Sin embargo, tiene ciertas limitaciones. Por un lado, como ya hemos visto, necesitamos la definición del modelo tanto a la hora de entrar como en producción. Esto no solo es engorroso y poco flexible, si no que sólo funcionará en entornos `Python` con `Pytorch` instalado. Si bien ésto es suficiente para, por ejemplo, poner nuestros modelos a trabajar en un servidor [Flask](https://sensioai.com/blog/052_produccion)), en muchas ocasiones necesitaremos ejecutar nuestras redes neuronales en otros entornos (smartphones, aplicaciones web, IoT, ...) en las que usaremos otros lenguajes de programación. Para ello, `Pytorch` nos permite `exportar` nuestro modelo en vez de simplemente `guradarlo`."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_KN7mv1pk64_"
      },
      "source": [
        "## Exportando modelos"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w2MsbPcWk64_"
      },
      "source": [
        "### Torchscript"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6nSy18Ugk64_"
      },
      "source": [
        "[Torchscript](https://pytorch.org/tutorials/beginner/Intro_to_TorchScript_tutorial.html) es una representación intermedia de un modelo de `Pytorch` que puede ejecutarse en diferentes entornos sin la necesidad de `Python`, por ejemplo en `C++`. Un modelo de `Pytorch` exportado en `torchscript` contiene los pesos de la red así como su definición (todas las operaciones que aplicaremos a un tensor desde la entrada hasta la salida). Tenemos dos maneras de exportar un modelo con `torchscript`:\n",
        "\n",
        "- `tracing`: Dada un entrada, se genera una representación del modelo de manera dinámica registrando todas las operaciones aplicadas al tensor hasta la salida. En este caso no seremos capaces de capturar diferentes caminos en nuestra red (*control flow*). Es la alternativa más eficiente, pero menos flexible.\n",
        "- `scripting`: Genera la representación intermedia de nuestra red neuronal directamente a partir del análisis de la misma, siendo capaz de capturar de manera fiel cualquier ramificación en la misma. No es tan eficiente, pero si más flexible."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "Vr4pzk9-k64_"
      },
      "outputs": [],
      "source": [
        "# tracing\n",
        "\n",
        "x = torch.rand(32, 1, 28, 28)\n",
        "traced_model = torch.jit.trace(model.cpu(), x)\n",
        "traced_model.save('model.zip')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "YSnZQ7wOk64_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6c575fc8-aa86-41f4-ae41-7053b5a9ee1d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "acc 0.81901: 100%|██████████| 2/2 [00:00<00:00, 31.52it/s]\n"
          ]
        }
      ],
      "source": [
        "loaded_model = torch.jit.load('model.zip')\n",
        "evaluate(loaded_model, dataloader)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "VRkafmlWk65A"
      },
      "outputs": [],
      "source": [
        "# scripting\n",
        "\n",
        "scripted_model = torch.jit.script(model.cpu())\n",
        "scripted_model.save('model.zip')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "a4UeNk3nk65A",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "553d8224-6e54-44bc-a1d9-d55d0f6532f7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "acc 0.81901: 100%|██████████| 2/2 [00:00<00:00, 33.18it/s]\n"
          ]
        }
      ],
      "source": [
        "loaded_model = torch.jit.load('model.zip')\n",
        "evaluate(loaded_model, dataloader)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FpaNboS2k65A"
      },
      "source": [
        "Exportar nuestro modelo nos aporta varias ventajas:\n",
        "\n",
        "- Ahora nuestro modelo puede ejecutarse en cualquier entorno capaz de interpretar la representación intermedia generada por `torchscript`, independientemente del hardware o software utilizado.\n",
        "- Nuestro modelo contiene los pesos y la definición de las operaciones, evitando tener que guardar código extra.\n",
        "- Esta representación intermedia puede ser optimizada de manera independiente, haciendo que nuestros modelos sean más rápidos.\n",
        "\n",
        "La principal desventaja es que al estar \"traduciendo\" `Python` a otro lenguaje, es posible que no todas las operaciones que queramos hacer estén soportadas."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "58rOHBXwk65A"
      },
      "source": [
        "> ⚡ Aprende más sobre `Torchscript`[aquí](https://pytorch.org/tutorials/beginner/Intro_to_TorchScript_tutorial.html)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-wdRwHzhk65A"
      },
      "source": [
        "Un consejo a tener en cuenta a la hora de exportar nuestros modelos que nos puede hacer la vida más fácil cuando pongamos nuestros modelos en producción, es incluir cualquier pre- o post-procesado de datos necesarios en el mismo modelo. Durante el entrenamiento no lo hacemos por motivos de eficiencia (queremos que nuestra `GPU` entrene la red lo más rápido posible mientras la `CPU` procesa cada batch de datos de manera paralela), pero estos procesados pueden ser costosos en producción (a veces incluso imposibles de realizar) por lo que incluirlos en el modelo es generalmente una buena idea.\n",
        "\n",
        "En este caso incluimos la normalización y preparación de los datos en un pre-procesado y calculamos una distribución de probabilidad sobre las salida con un post-procesado, que además también nos devuelve la clase con mayor probabilidad."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "AXG538DTk65A"
      },
      "outputs": [],
      "source": [
        "class Preprocessing(torch.nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "    def forward(self, x):\n",
        "        # esperamos un batch de imágenes sin normalizar\n",
        "        # normalización\n",
        "        x = (x / 255.)\n",
        "        x = (x - 0.1307) / 0.3081\n",
        "        # dimsensiones -> [bs, c, h, w]\n",
        "        x = x.unsqueeze(1)\n",
        "        # en imágenes en color, haríamos un `permute`\n",
        "        return x\n",
        "\n",
        "class Postprocessing(torch.nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.softmax = torch.nn.Softmax(dim=1)\n",
        "    def forward(self, x) :\n",
        "        # devolvemos distribución de probabilidad\n",
        "        # y clase con mayor probabilidad\n",
        "        return self.softmax(x), torch.argmax(x, dim=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "-mi3ypWyk65B"
      },
      "outputs": [],
      "source": [
        "final_model = torch.nn.Sequential(\n",
        "    Preprocessing(),\n",
        "    model.cpu(),\n",
        "    Postprocessing()\n",
        ")\n",
        "\n",
        "scripted_model = torch.jit.script(final_model)\n",
        "scripted_model.save('model.zip')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c8AWwm8qk65B"
      },
      "source": [
        "Ahora nuestro modelo acepta lotes de imágenes sin normalizar y con las dimensiones más comunes (alto, ancho) y devuelve una distribución de probabilidad. Es nuestro modelo quien se encarga del procesado."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "3lpMZEUck65B"
      },
      "outputs": [],
      "source": [
        "def script_evaluate(model, dataloader):\n",
        "    model = torch.jit.load(model)\n",
        "    model.cuda()\n",
        "    model.eval()\n",
        "    bar = tqdm(dataloader['test'])\n",
        "    acc = []\n",
        "    with torch.no_grad():\n",
        "        for batch in bar:\n",
        "            X, y = batch\n",
        "            # desnormalizar\n",
        "            X = (X*0.3081 + 0.1307)*255\n",
        "            # quitar dimensión canales\n",
        "            X = X.squeeze(1)\n",
        "            # el modelo pre-procesa\n",
        "            y_hat, label = model(X)\n",
        "            acc.append((y == label).sum().item() / len(y))\n",
        "            bar.set_description(f\"acc {np.mean(acc):.5f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "5oWAcIWrk65B",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cbc001c6-8c9b-4c67-ac4e-d86366edb680"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "acc 0.81901: 100%|██████████| 2/2 [00:00<00:00,  8.94it/s]\n"
          ]
        }
      ],
      "source": [
        "script_evaluate(\"model.zip\", dataloader)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r2Gcl4sEk65B"
      },
      "source": [
        "### ONNX"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5brZLUE8k65B"
      },
      "source": [
        "Si bien ahora nuestro modelo es capaz de ser importado y ejecutado de forma más flexible y eficiente, seguimos limitados por el hecho de necesitar `Pytorch` (o la librería `Torchscript` en `C++`) para ello. Por este motivo, `Pytorch` nos ofrece una última manera de exportar nuestros modelos a otra forma de representación intermedia conocida como [ONNX](https://onnx.ai/). Éste es un formato abierto con el espíritu de convertirse en un estándar de representación de redes neuronales. La gran mayoría de librerías y *frameworks* de `deep learning` soportan este formato, lo que implica que, por ejemplo, podemos entrenar un modelo en `Pytorch`, exportarlo en formato `ONNX` e importarlo en `Tensorflow` para ponerlo en producción (aunque `ONNX` también ofrece soluciones optimizadas para ello: `ONNX Runtime`). Así pues, exportar nuestros modelos a formato `ONNX` nos proporcionará la máxima flexibilidad, permitiéndonos, entre muchas otras cosas, ejecutar nuestras redes neuronales en entornos tales como navegadores web o IoT. Por contra, esta librería es la menos flexible en cuanto a cantidad y tipo de operaciones que podemos exportar, lo cual puede imponer unas restricciones muy grandes sobre nuestros modelos (aunque cada vez se soportan más)."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "os.kill(os.getpid(), 9)\n",
        "!pip install onnx"
      ],
      "metadata": {
        "id": "OeQ0KmKhx60P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KfP6Sz82k65B"
      },
      "outputs": [],
      "source": [
        "x = torch.rand(32, 1, 28, 28)\n",
        "y = model.cpu()(x)\n",
        "\n",
        "# exportamos el modelo\n",
        "torch.onnx.export(model,                     # el modelo\n",
        "                  x,                         # un ejemplo del input\n",
        "                  \"model.onnx\",              # el nombre del archivo para guardar el modelo\n",
        "                  export_params=True,        # guardar los pesos de la red\n",
        "                  opset_version=10,          # versión de ONNX\n",
        "                  do_constant_folding=True,  # optimizaciones\n",
        "                  input_names = ['input'],   # nombre de los inputs\n",
        "                  output_names = ['output'], # nombre de los outputs\n",
        "                  dynamic_axes={'input' : {0 : 'batch_size'},    # ejes con longitud variable (para poder usar diferentes tamaños de batch)\n",
        "                                'output' : {0 : 'batch_size'}})"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5CSKda8pk65B"
      },
      "source": [
        "Para poder ejecutar nuestro modelo necesitamos la librería de `ONNX Runtime` para `Python`, que puedes instalar con el comando `pip install onnxruntime`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ijFsVvt3k65B"
      },
      "outputs": [],
      "source": [
        "import onnxruntime\n",
        "\n",
        "def onnx_evaluate(model, dataloader):\n",
        "    # cargarmos el modelo\n",
        "    ort_session = onnxruntime.InferenceSession(model)\n",
        "    bar = tqdm(dataloader['test'])\n",
        "    acc = []\n",
        "    with torch.no_grad():\n",
        "        for batch in bar:\n",
        "            X, y = batch\n",
        "            X, y = X.numpy(), y.numpy()\n",
        "            # generamos los inputs\n",
        "            ort_inputs = {ort_session.get_inputs()[0].name: X}\n",
        "            # extraemos los outputs\n",
        "            ort_outs = ort_session.run(None, ort_inputs)[0]\n",
        "            acc.append((y == np.argmax(ort_outs, axis=1)).mean())\n",
        "            bar.set_description(f\"acc {np.mean(acc):.5f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "t6sv3Dozk65B"
      },
      "outputs": [],
      "source": [
        "onnx_evaluate(\"model.onnx\", dataloader)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PCwdUD8tk65B"
      },
      "source": [
        "De nuevo, te recomiendo incluir tanto pre- como post-procesado como parte del modelo para evitar problemas más adelante."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_SII_efck65B"
      },
      "source": [
        "> ⚡ Aprende más sobre `ONNX`[aquí](https://pytorch.org/tutorials/advanced/super_resolution_with_onnxruntime.html)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LAaOMeJ9k65C"
      },
      "source": [
        "## Resumen"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "shG9SYtTk65C"
      },
      "source": [
        "En este post hemos visto las diferentes manera que `Pytorch` nos ofrece a la hora de guardar y exportar nuestros modelos. Si en nuestro entorno de producción podemos usar `Python` e instalar `Pytorch`, entonces podemos simplemente `guardar` el `state_dict` de nuestro modelo, o incluso el modelo completo, y luego cargarlo en la aplicación. Ten en cuenta que necesitarás la definición de tu red neuronal (en nuestro ejemplo, la clase `Model`) que define las capas y operaciones que se aplican dada una entrada. Sin embargo, una opción más eficiente, consiste en `exportar` nuestro modelo con `torch.jit.trace` o `torch.jit.script` ya que luego podremos cargar nuestro modelos sin necesidad de arrastrar código y, además, podremos ejecutarlo en otros entornos como `C++`. Por último, si no puedes usar `Python` en tu aplicación, es muy posible que puedas usar `ONNX`, un formato estándar al que `Pytorch` nos permite también exportar."
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.3"
    },
    "toc": {
      "base_numbering": 1,
      "nav_menu": {},
      "number_sections": true,
      "sideBar": true,
      "skip_h1_title": false,
      "title_cell": "Table of Contents",
      "title_sidebar": "Contents",
      "toc_cell": false,
      "toc_position": {},
      "toc_section_display": true,
      "toc_window_display": true
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}