{"cells":[{"cell_type":"markdown","metadata":{"id":"pE_iwdR5m6xH"},"source":["[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/sensioai/blog/blob/master/028_pytorch_nn/pytorch_nn.ipynb)"]},{"cell_type":"markdown","metadata":{"id":"DjhgRWO_m6xK"},"source":["# Pytorch - Redes Neuronales"]},{"cell_type":"markdown","metadata":{"id":"CVNrcQ_5m6xK"},"source":["En el post [anterior](https://sensioai.com/blog/027_pytorch_intro) hicimos una introducción al framework de `redes neuronales` `Pytorch`. Hablamos de sus tres elementos fundamentales: el objeto `tensor` (similar al `array` de `NumPy`) `autograd` (que nos permite calcular derivadas de manera automáticas) y el soporte GPU. En este post vamos a entrar en detalle en la  funcionalidad que nos ofrece la librería para diseñar redes neuronales de manera flexible."]},{"cell_type":"code","execution_count":1,"metadata":{"ExecuteTime":{"end_time":"2020-08-15T12:21:45.471625Z","start_time":"2020-08-15T12:21:45.002765Z"},"id":"4hnzhQywm6xL","executionInfo":{"status":"ok","timestamp":1708948517985,"user_tz":240,"elapsed":4983,"user":{"displayName":"Miguel Angel Choque Garcia","userId":"17908264217194701994"}}},"outputs":[],"source":["import torch\n","\n","import pandas as pd\n","from sklearn.model_selection import train_test_split\n","from sklearn.preprocessing import LabelEncoder\n"]},{"cell_type":"markdown","metadata":{"heading_collapsed":true,"id":"IqUKyQ9Nm6xM"},"source":["## Modelos secuenciales"]},{"cell_type":"markdown","metadata":{"hidden":true,"id":"MDSz2Mbsm6xM"},"source":["La forma más sencilla de definir una `red neuronal` en `Pytorch` es utilizando la clase `Sequentail`. Esta clase nos permite definir una secuencia de capas, que se aplicarán de manera secuencial (las salidas de una capa serán la entrada de la siguiente). Ésto ya lo conocemos de posts anteriores, ya que es la forma ideal de definir un `Perceptrón Multicapa`."]},{"cell_type":"code","execution_count":2,"metadata":{"ExecuteTime":{"end_time":"2020-08-15T12:21:45.486329Z","start_time":"2020-08-15T12:21:45.472624Z"},"hidden":true,"id":"V5KEpUHVm6xN","executionInfo":{"status":"ok","timestamp":1708948517986,"user_tz":240,"elapsed":13,"user":{"displayName":"Miguel Angel Choque Garcia","userId":"17908264217194701994"}}},"outputs":[],"source":["D_in, H, D_out = 784, 100, 10\n","\n","model = torch.nn.Sequential(\n","    torch.nn.Linear(D_in, H),\n","    torch.nn.ReLU(),\n","    torch.nn.Linear(H, D_out),\n",")\n","\n","# D_in, H1, H2, D_out = 784, 100, 50, 10\n","# model = torch.nn.Sequential(\n","#     torch.nn.Linear(D_in, H1),\n","#     torch.nn.ReLU(),\n","#     torch.nn.Linear(H1, H2),\n","#     torch.nn.ReLU(),\n","#     torch.nn.Linear(H2, D_out),\n","# )\n"]},{"cell_type":"markdown","metadata":{"hidden":true,"id":"8Ea8TfSWm6xO"},"source":["El modelo anterior es un `MLP` con 784 entradas, 100 neuronas en la capa oculta y 10 salidas. Podemos usar este modelo para hacer un clasificador de imágenes con el dataset MNIST. Pero primero, vamos a ver como podemos calcular las salidas del modelo a partir de unas entradas de ejemplo."]},{"cell_type":"code","execution_count":3,"metadata":{"ExecuteTime":{"end_time":"2020-08-15T12:21:45.502329Z","start_time":"2020-08-15T12:21:45.487329Z"},"hidden":true,"id":"WVB30MPem6xO","outputId":"7b369f7d-3559-4de2-c933-10c873e2eee8","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1708948517987,"user_tz":240,"elapsed":12,"user":{"displayName":"Miguel Angel Choque Garcia","userId":"17908264217194701994"}}},"outputs":[{"output_type":"execute_result","data":{"text/plain":["torch.Size([64, 10])"]},"metadata":{},"execution_count":3}],"source":["outputs = model(torch.randn(64, 784))\n","outputs.shape"]},{"cell_type":"code","source":["print(outputs[0][:])"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"x7mk9EVzLeBV","executionInfo":{"status":"ok","timestamp":1708948517988,"user_tz":240,"elapsed":11,"user":{"displayName":"Miguel Angel Choque Garcia","userId":"17908264217194701994"}},"outputId":"0eccb181-f572-4ef1-8a03-1d443e6d46a6"},"execution_count":4,"outputs":[{"output_type":"stream","name":"stdout","text":["tensor([-0.0320, -0.0143,  0.1334, -0.3416, -0.4030,  0.2088,  0.3316,  0.1208,\n","        -0.1692, -0.4687], grad_fn=<SliceBackward0>)\n"]}]},{"cell_type":"markdown","metadata":{"hidden":true,"id":"I-J9Sa6Qm6xP"},"source":["Como puedes ver, simplemente le pasamos los inputs al modelo (llamándolo como una función). En este caso, usamos un tensor con 64 vectores de 784 valores. Es importante remarcar que los modelos de `Pytorch` (por lo general) siempre esperan que la primera dimensión sea la dimensión *batch*. Si queremos entrenar esta red en una GPU, es tan sencillo como"]},{"cell_type":"code","execution_count":5,"metadata":{"ExecuteTime":{"end_time":"2020-08-15T12:21:46.777020Z","start_time":"2020-08-15T12:21:45.503329Z"},"hidden":true,"id":"VjtJxIM_m6xQ","outputId":"54ef0997-e01b-4dc6-9fd0-ab507cacbec9","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1708948518453,"user_tz":240,"elapsed":473,"user":{"displayName":"Miguel Angel Choque Garcia","userId":"17908264217194701994"}}},"outputs":[{"output_type":"execute_result","data":{"text/plain":["Sequential(\n","  (0): Linear(in_features=784, out_features=100, bias=True)\n","  (1): ReLU()\n","  (2): Linear(in_features=100, out_features=10, bias=True)\n",")"]},"metadata":{},"execution_count":5}],"source":["model.to(\"cuda\")"]},{"cell_type":"markdown","metadata":{"hidden":true,"id":"ZxmpSqz6m6xQ"},"source":["Vamos a ver ahora como entrenar este modelo con el dataset MNIST."]},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"id":"fzLxwIznE6U5","executionInfo":{"status":"ok","timestamp":1708948520646,"user_tz":240,"elapsed":2197,"user":{"displayName":"Miguel Angel Choque Garcia","userId":"17908264217194701994"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"f01d6014-0e58-411e-b49c-ecd99ace9700"},"execution_count":6,"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"]}]},{"cell_type":"code","execution_count":7,"metadata":{"ExecuteTime":{"end_time":"2020-08-15T12:22:05.622262Z","start_time":"2020-08-15T12:21:46.778019Z"},"hidden":true,"id":"OmlXe8Gpm6xR","executionInfo":{"status":"ok","timestamp":1708948521827,"user_tz":240,"elapsed":1192,"user":{"displayName":"Miguel Angel Choque Garcia","userId":"17908264217194701994"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"99885637-476e-4121-bfaf-b9c7cc488214"},"outputs":[{"output_type":"stream","name":"stdout","text":["Forma de X: (10240, 784)\n","Forma de Y: (10240,)\n"]}],"source":["#from sklearn.datasets import fetch_openml\n","\n","# descarga datos\n","\n","mnist = pd.read_csv(\"/content/drive/MyDrive/Inteligencia Artificial 2/Datasets/Dig-MNIST.csv\")\n","\n","#X, Y = mnist[\"data\"], mnist[\"target\"]\n","#X.shape, Y.shape\n","\n","# Obtener características (píxeles) y etiquetas (números)\n","X = mnist.iloc[:, 1:].values  # Seleccionar todas las columnas excepto la primera como características\n","Y = mnist.iloc[:, 0].values   # Seleccionar la primera columna como etiquetas\n","\n","# Verificar las formas de X e Y\n","print(\"Forma de X:\", X.shape)\n","print(\"Forma de Y:\", Y.shape)"]},{"cell_type":"code","execution_count":8,"metadata":{"ExecuteTime":{"end_time":"2020-08-15T12:22:05.761911Z","start_time":"2020-08-15T12:22:05.624102Z"},"hidden":true,"id":"BzhE25udm6xR","executionInfo":{"status":"ok","timestamp":1708948521827,"user_tz":240,"elapsed":27,"user":{"displayName":"Miguel Angel Choque Garcia","userId":"17908264217194701994"}}},"outputs":[],"source":["import numpy as np\n","\n","# normalización y split\n","import numpy as np\n","x_2=np.array(X)\n","y_2=np.array(Y)\n","\n","# normalización y split\n","\n","X_train =x_2[:8000] / 255.\n","X_test =x_2[8000:] / 255.\n","y_train = y_2[:8000].astype(np.int32)\n","y_test = y_2[8000:].astype(np.int32)\n","\n","\n","\n","# X_train, X_test, y_train, y_test = X[:60000] / 255., X[60000:] / 255., Y[:60000].astype(np.float32), Y[60000:].astype(np.float32)"]},{"cell_type":"code","execution_count":9,"metadata":{"ExecuteTime":{"end_time":"2020-08-15T12:22:05.777964Z","start_time":"2020-08-15T12:22:05.763102Z"},"hidden":true,"id":"pDJK07Jpm6xR","executionInfo":{"status":"ok","timestamp":1708948521827,"user_tz":240,"elapsed":22,"user":{"displayName":"Miguel Angel Choque Garcia","userId":"17908264217194701994"}}},"outputs":[],"source":["# función de pérdida y derivada\n","\n","def softmax(x):\n","    return torch.exp(x) / torch.exp(x).sum(axis=-1,keepdims=True)\n","\n","def cross_entropy(output, target):\n","    logits = output[torch.arange(len(output)), target]\n","    loss = - logits + torch.log(torch.sum(torch.exp(output), axis=-1))\n","    loss = loss.mean()\n","    return loss"]},{"cell_type":"code","source":["# X_train"],"metadata":{"id":"E0mXU4_t5c-n","executionInfo":{"status":"ok","timestamp":1708948521827,"user_tz":240,"elapsed":21,"user":{"displayName":"Miguel Angel Choque Garcia","userId":"17908264217194701994"}}},"execution_count":10,"outputs":[]},{"cell_type":"code","source":["torch.cuda.is_available()"],"metadata":{"id":"qHL3LiGejvr0","executionInfo":{"status":"ok","timestamp":1708948521828,"user_tz":240,"elapsed":20,"user":{"displayName":"Miguel Angel Choque Garcia","userId":"17908264217194701994"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"da0195bf-9164-42e4-89dc-730d01ec9395"},"execution_count":11,"outputs":[{"output_type":"execute_result","data":{"text/plain":["True"]},"metadata":{},"execution_count":11}]},{"cell_type":"code","source":["print(X)"],"metadata":{"id":"tZCJjxDZyenK","executionInfo":{"status":"ok","timestamp":1708948521829,"user_tz":240,"elapsed":14,"user":{"displayName":"Miguel Angel Choque Garcia","userId":"17908264217194701994"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"859644eb-3ebe-4d14-d7e3-e966a4953acf"},"execution_count":12,"outputs":[{"output_type":"stream","name":"stdout","text":["[[0 0 0 ... 0 0 0]\n"," [0 0 0 ... 0 0 0]\n"," [0 0 0 ... 0 0 0]\n"," ...\n"," [0 0 0 ... 0 0 0]\n"," [0 0 0 ... 0 0 0]\n"," [0 0 0 ... 0 0 0]]\n"]}]},{"cell_type":"code","execution_count":13,"metadata":{"ExecuteTime":{"end_time":"2020-08-15T12:22:07.268014Z","start_time":"2020-08-15T12:22:05.778966Z"},"hidden":true,"id":"EjdhOJ90m6xS","executionInfo":{"status":"ok","timestamp":1708948528156,"user_tz":240,"elapsed":6337,"user":{"displayName":"Miguel Angel Choque Garcia","userId":"17908264217194701994"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"ea4e2766-1bc0-4160-d9d9-aa3d9163ef65"},"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 100/1000 Loss 0.74265\n","Epoch 200/1000 Loss 0.53530\n","Epoch 300/1000 Loss 0.42603\n","Epoch 400/1000 Loss 0.35249\n","Epoch 500/1000 Loss 0.29899\n","Epoch 600/1000 Loss 0.25860\n","Epoch 700/1000 Loss 0.22730\n","Epoch 800/1000 Loss 0.20249\n","Epoch 900/1000 Loss 0.18245\n","Epoch 1000/1000 Loss 0.16596\n"]}],"source":["# convertimos datos a tensores y copiamos en gpu\n","\n","X_t = torch.from_numpy(X_train).float().cuda()\n","Y_t = torch.from_numpy(y_train).long().cuda()\n","\n","# bucle entrenamiento\n","epochs = 1000\n","lr = 0.8\n","log_each = 100\n","l = []\n","for e in range(1, epochs + 1):\n","\n","    # forward\n","    y_pred = model(X_t)\n","\n","    # loss\n","    loss = cross_entropy(y_pred, Y_t)\n","    l.append(loss.item())\n","\n","    # ponemos a cero los gradientes\n","    model.zero_grad()\n","\n","    # Backprop (calculamos todos los gradientes automáticamente)\n","    loss.backward()\n","\n","    # update de los pesos\n","    with torch.no_grad():\n","        for param in model.parameters():\n","            param -= lr * param.grad\n","\n","    if not e % log_each:\n","        print(f\"Epoch {e}/{epochs} Loss {np.mean(l):.5f}\")"]},{"cell_type":"markdown","metadata":{"hidden":true,"id":"5tCiIuSvm6xT"},"source":["Como puedes observar en el ejemplo, podemos calcular la salida del modelo con una simple línea. Luego calculamos la función de pérdida, y llamando a la función `backward` `Pytorch` se encarga de calcular las derivadas de la misma con respecto a todos los parámetros del modelo automáticamente (si no queremos acumular estos gradientes, nos aseguramos de llamar a la función `zero_grad` para ponerlos a cero antes de calcularlos). Por útlimo, podemos iterar por los parámetros del modelo aplicando la regla de actualización deseada (en este caso usamos `descenso por gradiente`)."]},{"cell_type":"code","execution_count":14,"metadata":{"ExecuteTime":{"end_time":"2020-08-15T12:22:07.312014Z","start_time":"2020-08-15T12:22:07.270016Z"},"hidden":true,"id":"Ufomq0IIm6xT","executionInfo":{"status":"ok","timestamp":1708948528156,"user_tz":240,"elapsed":7,"user":{"displayName":"Miguel Angel Choque Garcia","userId":"17908264217194701994"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"0b3bdbcc-f670-468f-f98c-c2ee8dadb5d0"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["0.8816964285714286"]},"metadata":{},"execution_count":14}],"source":["from sklearn.metrics import accuracy_score\n","\n","def evaluate(x):\n","    model.eval()\n","    y_pred = model(x)\n","    y_probas = softmax(y_pred)\n","    return torch.argmax(y_probas, axis=1)\n","\n","y_pred = evaluate(torch.from_numpy(X_test).float().cuda())\n","accuracy_score(y_test, y_pred.cpu().numpy())"]},{"cell_type":"markdown","metadata":{"hidden":true,"id":"lafBMelim6xT"},"source":["Existen algunos tipos de capas que se comportan diferente en función de si estamos entrenando la red o usándola para generar predicciones. Podemos controlar el modo en el que queremos que esté nuestra red con las funciones `train` y `eval`."]},{"cell_type":"markdown","metadata":{"heading_collapsed":true,"id":"bQJhUWy2m6xT"},"source":["## Optimizadores y Funciones de pérdida"]},{"cell_type":"markdown","metadata":{"hidden":true,"id":"wnj54ahUm6xU"},"source":["En el ejemplo anterior hemos calculado la función de pérdida y aplicado la regla de optimización de forma manual. Sin embargo, `Pytorch` nos ofrece funcionalidad que nos abstrae estos cálculos ofreciendo además flexibilidad para aplicar diferentes funciones de pérdida o algoritmos de optimización de manera sencilla. Podemos encontrar diferentes funciones de pérdida ya implementadas en el paquete `torch.nn`."]},{"cell_type":"code","execution_count":15,"metadata":{"ExecuteTime":{"end_time":"2020-08-15T12:22:07.328014Z","start_time":"2020-08-15T12:22:07.313014Z"},"hidden":true,"id":"8ZmyhLd5m6xU","executionInfo":{"status":"ok","timestamp":1708948528157,"user_tz":240,"elapsed":5,"user":{"displayName":"Miguel Angel Choque Garcia","userId":"17908264217194701994"}}},"outputs":[],"source":["criterion = torch.nn.CrossEntropyLoss()"]},{"cell_type":"markdown","metadata":{"hidden":true,"id":"Yz70Aprzm6xU"},"source":["Mientras que los optimizadores se encuentran en el paquete `torch.optim`"]},{"cell_type":"code","execution_count":16,"metadata":{"ExecuteTime":{"end_time":"2020-08-15T12:22:07.343013Z","start_time":"2020-08-15T12:22:07.330016Z"},"hidden":true,"id":"X8-BU1mbm6xU","executionInfo":{"status":"ok","timestamp":1708948529595,"user_tz":240,"elapsed":1442,"user":{"displayName":"Miguel Angel Choque Garcia","userId":"17908264217194701994"}}},"outputs":[],"source":["optimizer = torch.optim.SGD(model.parameters(), lr=0.8)"]},{"cell_type":"markdown","metadata":{"hidden":true,"id":"GmOzqwGXm6xV"},"source":["Puedes ver la lista completa de funciones de pérdida y optimizadores disponibles en la [documentación](https://pytorch.org/docs/stable/index.html), aunque como ya has visto siempre puedes definir los tuyos propios fácilmente.\n","\n","Una vez definidos estos dos objetos, nuestro bucle de entrenamiento se simplifica considerablemente."]},{"cell_type":"code","execution_count":17,"metadata":{"ExecuteTime":{"end_time":"2020-08-15T12:22:08.626592Z","start_time":"2020-08-15T12:22:07.344013Z"},"code_folding":[0],"hidden":true,"id":"oz7CgSjum6xV","executionInfo":{"status":"ok","timestamp":1708948529596,"user_tz":240,"elapsed":16,"user":{"displayName":"Miguel Angel Choque Garcia","userId":"17908264217194701994"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"ebede3e5-1632-458e-8ba7-f3779df8a7bb"},"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 10/100 Loss 1.75849\n","Epoch 20/100 Loss 1.51942\n","Epoch 30/100 Loss 1.27767\n","Epoch 40/100 Loss 1.11866\n","Epoch 50/100 Loss 1.01043\n","Epoch 60/100 Loss 0.92837\n","Epoch 70/100 Loss 0.86763\n","Epoch 80/100 Loss 0.81892\n","Epoch 90/100 Loss 0.77679\n","Epoch 100/100 Loss 0.74104\n"]},{"output_type":"execute_result","data":{"text/plain":["0.8357142857142857"]},"metadata":{},"execution_count":17}],"source":["D_in, H, D_out = 784, 100, 10\n","\n","model = torch.nn.Sequential(\n","    torch.nn.Linear(D_in, H),\n","    torch.nn.ReLU(),\n","    torch.nn.Linear(H, D_out),\n",").to(\"cuda\")\n","\n","criterion = torch.nn.CrossEntropyLoss()\n","optimizer = torch.optim.SGD(model.parameters(), lr=0.8)\n","\n","epochs = 100\n","log_each = 10\n","l = []\n","model.train()\n","for e in range(1, epochs+1):\n","\n","    # forward\n","    y_pred = model(X_t)\n","\n","    # loss\n","    loss = criterion(y_pred, Y_t)\n","    l.append(loss.item())\n","\n","    # ponemos a cero los gradientes\n","    optimizer.zero_grad()\n","\n","    # Backprop (calculamos todos los gradientes automáticamente)\n","    loss.backward()\n","\n","    # update de los pesos\n","    optimizer.step()\n","\n","    if not e % log_each:\n","        print(f\"Epoch {e}/{epochs} Loss {np.mean(l):.5f}\")\n","\n","y_pred = evaluate(torch.from_numpy(X_test).float().cuda())\n","accuracy_score(y_test, y_pred.cpu().numpy())"]},{"cell_type":"markdown","metadata":{"heading_collapsed":true,"id":"ipyuFlAIm6xV"},"source":["## Modelos custom"]},{"cell_type":"markdown","metadata":{"hidden":true,"id":"_uh7djQTm6xV"},"source":["Si bien en muchos casos definir una `red neuronal` como una secuencia de capas es suficiente, en otros casos será un factor limitante. Un ejemplo son las redes residuales, en las que no sólo utilizamos la salida de una capa para alimentar la siguiente si no que, además, le sumamos su propia entrada. Este tipo de arquitectura no puede ser definida con la clase `Sequential`, y para ello necesitamos hacer un modelo *customizado*. Para ello, `Pytroch` nos ofrece la siguiente sintaxis."]},{"cell_type":"code","execution_count":18,"metadata":{"ExecuteTime":{"end_time":"2020-08-15T12:22:08.642713Z","start_time":"2020-08-15T12:22:08.628592Z"},"hidden":true,"id":"zP6-77c5m6xW","executionInfo":{"status":"ok","timestamp":1708948529596,"user_tz":240,"elapsed":10,"user":{"displayName":"Miguel Angel Choque Garcia","userId":"17908264217194701994"}}},"outputs":[],"source":["# creamos una clase que hereda de `torch.nn.Module`\n","\n","class ModeloPersonalizado(torch.nn.Module):\n","\n","    # constructor\n","    def __init__(self, D_in, H, D_out):\n","\n","        # llamamos al constructor de la clase madre\n","        super(ModeloPersonalizado, self).__init__()\n","\n","        # definimos nuestras capas\n","        self.fc1 = torch.nn.Linear(D_in, H)\n","        self.relu = torch.nn.ReLU()\n","        self.fc2 = torch.nn.Linear(H, D_out)\n","\n","    # lógica para calcular las salidas de la red\n","    def forward(self, x):\n","        x = self.fc1(x)\n","        x = self.relu(x)\n","        x = self.fc2(x)\n","        return x"]},{"cell_type":"markdown","metadata":{"hidden":true,"id":"2jwizXIgm6xW"},"source":["En primer lugar, necesitamos definir una nueva clase que herede de la clase `torch.nn.Module`. Esta clase madre aportará toda la funcionalidad esencial que necesita una `red neuronal` (soporte GPU, iterar por sus parámeteros, etc). Luego, en esta clase necesitamos definir mínimos dos funciones:\n","\n","- `init`: en el constructor llamaremos al constructor de la clase madre y después definiremos todas las capas que querramos usar en la red.\n","- `forward`: en esta función definimos toda la lógica que aplicaremos desde que recibimos los inputs hasta que devolvemos los outputs.\n","\n","En el ejemplo anterior simplemente hemos replicado la misma red (puedes conseguir el mismo efecto usando la clase `Sequential`)."]},{"cell_type":"code","execution_count":19,"metadata":{"ExecuteTime":{"end_time":"2020-08-15T12:22:08.658711Z","start_time":"2020-08-15T12:22:08.644712Z"},"hidden":true,"id":"zhaXSvoVm6xW","executionInfo":{"status":"ok","timestamp":1708948529596,"user_tz":240,"elapsed":10,"user":{"displayName":"Miguel Angel Choque Garcia","userId":"17908264217194701994"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"1068c726-55d6-4846-942d-bdc35b3a3f46"},"outputs":[{"output_type":"stream","name":"stdout","text":["tensor([[-0.7975,  0.4020, -0.0529,  ...,  0.2093,  0.0839, -0.5453],\n","        [ 0.3251, -1.3477,  0.1486,  ...,  0.2561,  0.5434, -0.0507],\n","        [ 0.2910,  0.4904, -1.4660,  ..., -1.5387, -0.0908, -1.9974],\n","        ...,\n","        [ 1.2251,  1.4736,  0.4680,  ..., -2.1641, -0.1409, -1.3830],\n","        [-0.3671, -1.0128,  1.1067,  ..., -1.3502,  0.7997,  1.3077],\n","        [-1.6358, -0.3203,  0.9018,  ..., -1.3204, -0.0964,  0.9090]])\n"]},{"output_type":"execute_result","data":{"text/plain":["torch.Size([64, 10])"]},"metadata":{},"execution_count":19}],"source":["model = ModeloPersonalizado(784, 100, 10)\n","# Codigo para saber si el modelo esta votando los datos en las cantidades correctas\n","x_prueba = torch.randn(64, 784)\n","print(x_prueba)\n","outputs = model(x_prueba)\n","outputs.shape"]},{"cell_type":"markdown","metadata":{"hidden":true,"id":"_RkPO5hum6xW"},"source":["Ahora, podemos entrenar nuestra red de la misma forma que lo hemos hecho anteriormente."]},{"cell_type":"code","execution_count":20,"metadata":{"ExecuteTime":{"end_time":"2020-08-15T12:22:09.941710Z","start_time":"2020-08-15T12:22:08.659711Z"},"hidden":true,"id":"idh4YMn6m6xX","executionInfo":{"status":"ok","timestamp":1708948529862,"user_tz":240,"elapsed":273,"user":{"displayName":"Miguel Angel Choque Garcia","userId":"17908264217194701994"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"f8d20b15-648b-4808-ada6-af695dfa5c1c"},"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 10/100 Loss 1.72759\n","Epoch 20/100 Loss 1.46506\n","Epoch 30/100 Loss 1.25185\n","Epoch 40/100 Loss 1.10039\n","Epoch 50/100 Loss 0.99366\n","Epoch 60/100 Loss 0.91643\n","Epoch 70/100 Loss 0.85574\n","Epoch 80/100 Loss 0.80673\n","Epoch 90/100 Loss 0.76594\n","Epoch 100/100 Loss 0.73114\n"]},{"output_type":"execute_result","data":{"text/plain":["0.8308035714285714"]},"metadata":{},"execution_count":20}],"source":["model.to(\"cuda\")\n","criterion = torch.nn.CrossEntropyLoss()\n","optimizer = torch.optim.SGD(model.parameters(), lr=0.8)\n","\n","epochs = 100\n","log_each = 10\n","l = []\n","model.train()\n","for e in range(1, epochs+1):\n","\n","    # forward\n","    y_pred = model(X_t)\n","\n","    # loss\n","    loss = criterion(y_pred, Y_t)\n","    l.append(loss.item())\n","\n","    # ponemos a cero los gradientes\n","    optimizer.zero_grad()\n","\n","    # Backprop (calculamos todos los gradientes automáticamente)\n","    loss.backward()\n","\n","    # update de los pesos\n","    optimizer.step()\n","\n","    if not e % log_each:\n","        print(f\"Epoch {e}/{epochs} Loss {np.mean(l):.5f}\")\n","\n","y_pred = evaluate(torch.from_numpy(X_test).float().cuda())\n","accuracy_score(y_test, y_pred.cpu().numpy())"]},{"cell_type":"markdown","metadata":{"hidden":true,"id":"Rh3bxMrmm6xX"},"source":["Aquí puedes ver otro ejemplo de como definir un `MLP` con conexiones residuales, algo que no podemos hacer simplemente usando un modelo secuencial."]},{"cell_type":"code","execution_count":21,"metadata":{"ExecuteTime":{"end_time":"2020-08-15T12:22:09.956710Z","start_time":"2020-08-15T12:22:09.942710Z"},"hidden":true,"id":"l-6qAZn1m6xX","executionInfo":{"status":"ok","timestamp":1708948529863,"user_tz":240,"elapsed":15,"user":{"displayName":"Miguel Angel Choque Garcia","userId":"17908264217194701994"}}},"outputs":[],"source":["class ModelCustom2(torch.nn.Module):\n","\n","    def __init__(self, D_in, H, D_out):\n","        super(ModelCustom2, self).__init__()\n","        self.fc1 = torch.nn.Linear(D_in, H)\n","        self.relu = torch.nn.ReLU()\n","        self.fc2 = torch.nn.Linear(H, D_out)\n","\n","    def forward(self, x):\n","        x1 = self.fc1(x)\n","        x = self.relu(x1)\n","        x = self.fc2(x + x1)\n","        return x"]},{"cell_type":"code","execution_count":33,"metadata":{"ExecuteTime":{"end_time":"2020-08-15T12:22:11.314772Z","start_time":"2020-08-15T12:22:09.958712Z"},"hidden":true,"id":"EaSLokO7m6xX","executionInfo":{"status":"ok","timestamp":1708948570215,"user_tz":240,"elapsed":11676,"user":{"displayName":"Miguel Angel Choque Garcia","userId":"17908264217194701994"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"0cd0c6b5-367b-475c-e5a6-7db5704efd2b"},"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 100/1000 Loss 0.83160\n","Epoch 200/1000 Loss 0.65934\n","Epoch 300/1000 Loss 0.57929\n","Epoch 400/1000 Loss 0.52728\n","Epoch 500/1000 Loss 0.48784\n","Epoch 600/1000 Loss 0.45597\n","Epoch 700/1000 Loss 0.42853\n","Epoch 800/1000 Loss 0.40555\n","Epoch 900/1000 Loss 0.38300\n","Epoch 1000/1000 Loss 0.36265\n"]},{"output_type":"execute_result","data":{"text/plain":["0.8455357142857143"]},"metadata":{},"execution_count":33}],"source":["model = ModelCustom2(784, 1000, 100).to(\"cuda\")\n","criterion = torch.nn.CrossEntropyLoss()\n","optimizer = torch.optim.SGD(model.parameters(), lr=0.2)\n","\n","epochs = 1000\n","log_each = 100\n","l = []\n","model.train()\n","for e in range(1, epochs+1):\n","\n","    # forward\n","    y_pred = model(X_t)\n","\n","    # loss\n","    loss = criterion(y_pred, Y_t)\n","    l.append(loss.item())\n","\n","    # ponemos a cero los gradientes\n","    optimizer.zero_grad()\n","\n","    # Backprop (calculamos todos los gradientes automáticamente)\n","    loss.backward()\n","\n","    # update de los pesos\n","    optimizer.step()\n","\n","    if not e % log_each:\n","        print(f\"Epoch {e}/{epochs} Loss {np.mean(l):.5f}\")\n","\n","y_pred = evaluate(torch.from_numpy(X_test).float().cuda())\n","accuracy_score(y_test, y_pred.cpu().numpy())"]},{"cell_type":"markdown","metadata":{"hidden":true,"id":"sgoJC4nIm6xY"},"source":["De esta manera, tenemos mucha flexibilidad para definir nuestras redes."]},{"cell_type":"markdown","metadata":{"heading_collapsed":true,"id":"s1ZrxJsJm6xY"},"source":["## Accediendo a las capas de una red"]},{"cell_type":"markdown","metadata":{"hidden":true,"id":"TC470LoYm6xY"},"source":["En ocasiones queremos acceder a una capa en particular de nuestra red. Para ello, podemos acceder utilizando su nombre."]},{"cell_type":"code","execution_count":34,"metadata":{"ExecuteTime":{"end_time":"2020-08-15T12:22:11.329809Z","start_time":"2020-08-15T12:22:11.316772Z"},"hidden":true,"id":"K5VAtILVm6xY","executionInfo":{"status":"ok","timestamp":1708948578899,"user_tz":240,"elapsed":421,"user":{"displayName":"Miguel Angel Choque Garcia","userId":"17908264217194701994"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"71dac28d-75bb-4fed-d9de-0bc0c56a4837"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["ModelCustom2(\n","  (fc1): Linear(in_features=784, out_features=1000, bias=True)\n","  (relu): ReLU()\n","  (fc2): Linear(in_features=1000, out_features=100, bias=True)\n",")"]},"metadata":{},"execution_count":34}],"source":["model"]},{"cell_type":"code","execution_count":35,"metadata":{"ExecuteTime":{"end_time":"2020-08-15T12:22:11.345809Z","start_time":"2020-08-15T12:22:11.332809Z"},"hidden":true,"id":"_EfUdON5m6xY","executionInfo":{"status":"ok","timestamp":1708948585403,"user_tz":240,"elapsed":460,"user":{"displayName":"Miguel Angel Choque Garcia","userId":"17908264217194701994"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"4b4e40c3-1e9f-4fe0-e2bf-de1cc20c6887"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["Linear(in_features=784, out_features=1000, bias=True)"]},"metadata":{},"execution_count":35}],"source":["model.fc1"]},{"cell_type":"markdown","metadata":{"hidden":true,"id":"5vXjUwhmm6xZ"},"source":["También podemos acceder directamente a los tensores que contienen los parámetros con las propiedades adecuadas"]},{"cell_type":"code","execution_count":36,"metadata":{"ExecuteTime":{"end_time":"2020-08-15T12:22:11.360809Z","start_time":"2020-08-15T12:22:11.346809Z"},"hidden":true,"id":"C6Wy_6cXm6xZ","executionInfo":{"status":"ok","timestamp":1708948587385,"user_tz":240,"elapsed":325,"user":{"displayName":"Miguel Angel Choque Garcia","userId":"17908264217194701994"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"13579344-23d6-4bae-815c-e58af2dfa769"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["Parameter containing:\n","tensor([[-0.0240, -0.0170,  0.0186,  ..., -0.0323, -0.0330,  0.0239],\n","        [-0.0343,  0.0234, -0.0025,  ...,  0.0221,  0.0239,  0.0194],\n","        [-0.0074, -0.0105,  0.0272,  ...,  0.0262,  0.0007, -0.0081],\n","        ...,\n","        [-0.0058,  0.0116,  0.0242,  ...,  0.0322,  0.0009,  0.0165],\n","        [ 0.0114, -0.0101,  0.0169,  ..., -0.0071,  0.0196, -0.0298],\n","        [-0.0342,  0.0331, -0.0042,  ...,  0.0179, -0.0179,  0.0059]],\n","       device='cuda:0', requires_grad=True)"]},"metadata":{},"execution_count":36}],"source":["model.fc1.weight"]},{"cell_type":"code","execution_count":37,"metadata":{"ExecuteTime":{"end_time":"2020-08-15T12:22:11.375809Z","start_time":"2020-08-15T12:22:11.361809Z"},"hidden":true,"id":"5TbpHDGKm6xZ","executionInfo":{"status":"ok","timestamp":1708948589009,"user_tz":240,"elapsed":299,"user":{"displayName":"Miguel Angel Choque Garcia","userId":"17908264217194701994"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"006ff293-3445-419b-d5d5-932bdf6349e7"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["Parameter containing:\n","tensor([-5.5942e-03,  4.1684e-02,  2.0842e-02, -2.3471e-02,  2.7334e-02,\n","         4.1995e-02,  1.6146e-02,  6.7494e-04, -2.2498e-02,  6.7495e-02,\n","         3.5134e-02, -5.1514e-02, -2.2364e-02,  6.2335e-02, -1.8160e-03,\n","        -1.0916e-01,  5.8423e-02,  2.0487e-02,  1.0419e-01, -1.4122e-02,\n","        -1.9191e-02, -1.5970e-01, -2.9123e-02, -2.6600e-02,  1.0052e-01,\n","        -7.9297e-02, -5.5097e-02,  5.6630e-03,  7.1414e-03, -7.0787e-03,\n","        -6.7167e-02, -9.2235e-02,  6.3453e-02,  3.7388e-02, -8.6513e-02,\n","        -9.7600e-02,  3.0909e-02, -1.5245e-02,  3.8811e-02, -1.4016e-02,\n","         3.1801e-03, -3.9992e-02,  3.6655e-02, -4.4679e-03, -2.6743e-02,\n","         8.1266e-03,  8.5863e-02,  9.1428e-03,  2.2186e-02,  5.3463e-02,\n","         2.1230e-02,  3.2582e-02, -5.6709e-03,  2.6060e-02, -2.5412e-03,\n","        -4.1327e-02, -1.1163e-03, -1.9972e-02,  1.0996e-01, -1.9625e-02,\n","         9.2916e-04, -1.1607e-01,  5.0887e-02, -2.1630e-02, -5.2308e-02,\n","         1.4197e-02,  1.2032e-01,  2.0791e-02,  2.8836e-02, -3.3018e-02,\n","        -5.2562e-02,  7.4416e-02,  9.8640e-03,  4.6210e-02, -1.6479e-01,\n","         8.7640e-02, -1.8053e-02,  2.7929e-02,  5.7232e-02,  7.7026e-02,\n","        -4.0535e-02,  5.9047e-02, -9.5616e-03,  8.7822e-03,  1.1520e-03,\n","         7.2891e-02,  2.9890e-02, -2.5715e-03, -7.2994e-02, -2.6382e-02,\n","         1.2198e-01,  4.3663e-02,  1.4465e-02,  1.1623e-02,  2.7990e-02,\n","         1.4280e-01,  1.6035e-01,  7.5568e-02, -1.6252e-02,  7.6695e-02,\n","         2.1071e-02, -1.1635e-01, -2.9013e-02,  1.5536e-02,  5.0484e-02,\n","         1.1218e-03,  3.5182e-02,  9.6387e-02,  1.2541e-02, -1.5001e-02,\n","        -2.8834e-02, -8.9179e-02, -8.7775e-02, -2.2350e-05,  9.6595e-02,\n","         1.6459e-01,  2.3120e-03,  1.0641e-01,  1.1900e-01,  7.3957e-02,\n","        -4.0066e-02, -9.5607e-03, -3.2879e-02, -1.8523e-01,  5.4201e-03,\n","        -1.0808e-02,  6.1460e-02, -1.5867e-02, -4.7961e-02,  3.2117e-02,\n","        -3.7548e-02,  6.3376e-02, -3.3667e-02,  4.3903e-02,  2.3427e-02,\n","        -9.9108e-03, -8.1394e-02,  5.8547e-02, -6.7071e-02, -5.7106e-03,\n","         2.8504e-02, -4.8818e-02,  7.1020e-02,  1.7675e-02, -2.6474e-02,\n","         1.1938e-01,  4.9278e-02, -1.0397e-02, -9.8560e-04,  2.0073e-03,\n","        -2.7306e-02,  7.5430e-02,  7.1129e-02,  2.8436e-02, -2.0950e-02,\n","        -3.4441e-02,  1.0824e-02, -3.6078e-02,  1.0443e-01,  4.4601e-02,\n","         9.0286e-02, -1.9713e-02, -3.3451e-03,  4.7296e-02, -7.1381e-02,\n","         8.8362e-02,  3.0245e-02,  5.2520e-02, -4.7642e-02,  7.7681e-02,\n","         4.9774e-02,  2.2425e-02, -2.3606e-02,  2.9951e-02,  4.0151e-02,\n","         7.5844e-02, -9.6784e-02,  6.5093e-02,  2.5385e-03, -5.2221e-02,\n","        -1.4533e-02,  1.1237e-02, -3.5071e-02, -5.9013e-02,  5.4068e-02,\n","         6.7098e-02,  3.5242e-02,  4.1272e-02,  3.8406e-02, -4.4543e-02,\n","         1.0270e-01,  6.1504e-02,  6.0038e-03, -2.0312e-02, -3.0647e-02,\n","         1.1457e-01,  4.7735e-02,  1.3705e-01, -1.1059e-02, -3.2606e-02,\n","        -5.6661e-02,  1.6189e-02, -8.4571e-02,  3.9794e-02,  1.0738e-02,\n","         1.0057e-01, -9.8210e-03,  8.6388e-02,  1.4958e-02, -6.3411e-03,\n","         5.5543e-02, -2.3538e-02, -2.9981e-02,  9.1162e-02,  2.7253e-02,\n","         3.7369e-02,  2.8333e-02,  2.5071e-02, -1.3630e-02,  3.1480e-02,\n","         1.1515e-03,  1.2616e-02, -1.1038e-02, -4.4196e-02,  1.0134e-01,\n","         4.3754e-02,  5.9624e-03, -6.5275e-02,  6.0929e-02,  4.4834e-02,\n","        -4.7999e-02,  4.3709e-02,  5.6534e-02,  6.7164e-03,  2.2563e-02,\n","        -3.1195e-02, -4.6990e-02,  2.0999e-02,  4.1188e-02, -1.1379e-03,\n","        -1.6054e-02, -8.0796e-03, -2.1956e-02,  1.2793e-02,  6.5542e-02,\n","         1.4006e-02,  5.7334e-02,  7.8522e-02,  4.4897e-02,  1.3932e-02,\n","         1.3570e-01, -3.7781e-03,  3.1824e-03,  3.1227e-02, -3.2303e-02,\n","         1.1371e-01,  1.5648e-02, -2.9059e-02, -7.1981e-02,  3.2340e-02,\n","        -6.6708e-03, -3.8633e-05,  2.0355e-02,  5.2554e-03,  2.4329e-02,\n","        -1.7649e-02, -1.7081e-02, -5.3003e-02,  4.3642e-02, -1.0411e-02,\n","        -6.6141e-02,  7.4435e-02,  4.6111e-02, -4.5020e-02,  4.2885e-02,\n","        -3.3017e-02,  9.5690e-02,  3.7406e-02,  3.6582e-02,  1.2016e-02,\n","        -1.1043e-01,  6.7310e-02,  4.1038e-02, -2.5521e-02,  7.6167e-02,\n","        -7.9504e-02, -1.4720e-03,  1.0513e-01,  4.1159e-02,  8.2419e-03,\n","         1.3660e-01, -1.7764e-02,  7.4167e-03, -1.6509e-02,  7.0258e-02,\n","         2.2950e-02, -4.3482e-03, -3.6308e-02,  6.2489e-03,  4.3070e-02,\n","         5.0539e-02,  3.8744e-02,  1.0205e-02,  6.3668e-02,  7.9300e-02,\n","         3.2065e-03,  2.9032e-02,  2.3702e-02,  2.4949e-02, -1.6078e-02,\n","         6.1210e-02,  7.4545e-02, -2.0838e-02,  1.4380e-01,  4.2164e-02,\n","         3.1341e-02,  4.1659e-02,  1.9643e-02,  5.4584e-03, -6.0729e-03,\n","         2.8104e-02,  1.8620e-02,  5.4310e-02, -5.5541e-03, -2.4689e-02,\n","        -5.3294e-02,  5.9606e-02,  1.1818e-01,  6.1227e-02,  9.7121e-02,\n","         1.0287e-01,  7.4445e-03,  3.0179e-02, -1.7414e-02,  3.0477e-02,\n","         7.6829e-02, -3.6455e-02,  4.0877e-02,  3.2078e-02,  9.7099e-02,\n","         3.2823e-03,  1.6321e-02,  4.6734e-02,  9.6948e-03,  7.2314e-02,\n","        -1.5665e-02, -3.7670e-02, -1.0431e-02,  5.7218e-02,  2.7832e-02,\n","        -1.4192e-02,  6.0654e-02,  3.9118e-02, -3.4517e-02, -7.6414e-02,\n","         7.1011e-02, -7.1146e-03,  2.1398e-02, -2.0652e-02, -5.2238e-02,\n","        -3.2828e-02,  1.2561e-01,  1.2653e-01, -5.5154e-02, -6.3852e-02,\n","        -2.8679e-03,  8.6633e-02,  1.4808e-02, -1.2045e-02,  1.0453e-01,\n","        -5.5065e-02,  1.1355e-01,  2.2620e-02, -3.4489e-02,  8.1872e-02,\n","         6.0452e-02, -9.9124e-03,  1.5808e-02,  3.1019e-02,  2.6147e-02,\n","         8.3502e-02, -4.7784e-02, -3.5135e-02,  7.1266e-02,  4.8727e-02,\n","        -4.8251e-02,  3.6165e-02, -3.2938e-02,  2.2193e-02,  6.2057e-02,\n","         8.9217e-02, -7.5759e-02, -9.4416e-02,  2.3858e-02,  7.1205e-02,\n","         4.8692e-02, -4.9942e-02, -3.2587e-03,  8.6512e-02, -8.5870e-03,\n","         8.6477e-02,  5.1293e-02, -1.9425e-02,  2.6143e-02, -9.4415e-03,\n","         5.3605e-02,  1.6129e-02,  2.0784e-02,  3.1002e-02, -1.7377e-02,\n","        -3.0241e-02, -2.0803e-02,  7.3172e-02, -6.8584e-02,  4.2924e-02,\n","         5.5118e-02, -2.6390e-02, -7.5786e-03,  2.1814e-02, -5.6845e-02,\n","        -8.8488e-02,  3.1049e-02,  1.6222e-01,  1.7803e-02,  9.1348e-02,\n","         9.3238e-02,  1.4742e-01,  3.0505e-02, -2.9906e-03,  5.2549e-02,\n","        -4.3083e-02,  1.5831e-01, -4.9328e-02, -9.6301e-04,  3.8628e-02,\n","        -5.4703e-02,  1.0040e-02,  6.3265e-02, -5.9776e-03,  1.6815e-02,\n","        -2.6093e-02, -4.7435e-02,  3.1716e-02, -9.0003e-03,  7.3739e-02,\n","        -3.4858e-02,  1.0778e-01,  1.1148e-01,  8.6062e-02, -3.0481e-02,\n","        -6.9965e-02,  3.5862e-02, -1.3480e-02,  7.3356e-02,  1.4018e-02,\n","         7.5262e-02,  1.7745e-02,  1.2251e-01, -1.3279e-02,  1.1104e-01,\n","        -6.0417e-02,  1.6862e-02,  2.7791e-02,  4.6019e-02,  7.4396e-02,\n","        -3.0466e-02,  1.7479e-01, -6.5346e-03,  3.5465e-02,  1.0574e-01,\n","         6.1298e-02,  6.8945e-03, -1.8171e-02,  4.1218e-02, -8.8535e-03,\n","         8.5930e-03,  2.5794e-02,  6.6326e-02,  1.2827e-02,  9.0926e-02,\n","         1.0255e-01,  1.1422e-01,  7.7341e-02, -1.0953e-01, -1.1307e-03,\n","         9.8188e-02, -2.9115e-02, -3.4416e-02, -1.7566e-02,  2.1110e-03,\n","        -1.4398e-02, -5.4085e-02, -3.8181e-02,  5.0707e-02, -2.0952e-02,\n","        -7.7822e-02, -7.5442e-02, -5.0099e-02, -5.6765e-02, -2.6706e-02,\n","        -7.6418e-02, -7.3583e-02,  1.5358e-02,  2.9717e-04, -1.6784e-02,\n","        -2.6620e-02, -3.0342e-02, -5.0680e-02, -1.8095e-02, -1.4638e-02,\n","         5.0024e-02,  8.3481e-02,  1.3587e-01, -4.2589e-02, -1.7415e-02,\n","         5.4539e-02, -5.0112e-02,  6.3536e-02,  3.3458e-02,  1.4141e-01,\n","         2.6632e-02,  5.9235e-02, -6.2644e-03, -1.6840e-02,  5.7355e-02,\n","         8.9648e-02,  1.1034e-02,  4.5252e-02,  1.1673e-01, -6.6827e-03,\n","         4.1700e-03,  3.1602e-02,  4.0237e-03,  1.4475e-02, -2.7589e-02,\n","        -2.6355e-02,  1.8583e-02, -4.1333e-02, -4.9320e-02,  2.5097e-02,\n","         3.0263e-02,  2.0072e-02,  1.5403e-02, -3.2959e-03,  1.5456e-01,\n","         7.8344e-02, -1.7967e-03, -1.4685e-02,  2.7730e-02, -2.0278e-02,\n","         6.2932e-02, -2.4848e-02, -5.5388e-02, -1.1470e-01,  1.5268e-02,\n","         1.6851e-02,  2.7243e-02,  5.3151e-02, -6.1564e-02, -6.9335e-02,\n","        -3.1895e-02,  1.0396e-03,  1.8195e-02, -2.9081e-02,  3.6058e-02,\n","         3.8492e-02, -3.6810e-02, -7.1908e-02, -1.9695e-02, -5.1223e-02,\n","        -6.9777e-02,  1.4728e-02, -1.7354e-02,  3.2634e-02,  2.2031e-02,\n","         4.1181e-02, -1.8475e-02, -5.0469e-02,  7.4134e-02, -8.7001e-02,\n","         4.1701e-02, -7.9603e-02,  1.2600e-01,  1.6939e-01, -1.9395e-02,\n","         1.5225e-02, -5.0772e-02, -1.8741e-03,  1.1047e-01,  5.1654e-04,\n","         1.3500e-02, -1.4961e-02,  4.7668e-02,  4.5624e-02,  2.6706e-04,\n","         8.5529e-02,  1.3097e-01, -3.2103e-02, -3.7173e-03, -2.3283e-02,\n","        -8.1348e-03,  7.2767e-02,  1.4450e-02,  1.0920e-01,  3.2903e-02,\n","        -3.1450e-02, -7.3859e-03,  5.2435e-02,  2.8102e-02,  2.5864e-02,\n","        -7.7861e-02, -3.9395e-02, -4.9603e-03,  6.8948e-02, -8.8200e-04,\n","         7.3583e-02,  1.0940e-01,  5.6413e-02,  1.3081e-02,  3.3677e-02,\n","        -5.7367e-02,  1.4752e-02,  2.4064e-02,  8.8915e-02,  5.2222e-02,\n","         4.1035e-02,  4.0101e-02,  5.3391e-02, -1.3610e-02, -6.2046e-02,\n","        -4.9161e-02,  9.6111e-03, -5.2879e-03,  7.1140e-02,  8.1043e-03,\n","        -7.3444e-02, -6.6318e-02, -8.4618e-02,  1.4773e-02,  1.2222e-01,\n","         8.1880e-03, -3.1083e-02, -9.5771e-02, -6.0357e-02, -3.9078e-02,\n","        -5.1074e-02,  5.2955e-02, -1.7384e-03,  3.0340e-03,  9.7661e-02,\n","         4.5662e-02,  2.1206e-02, -4.3932e-02, -2.9006e-02,  1.2920e-02,\n","         3.1742e-02,  5.2403e-02, -1.3863e-02,  2.6308e-02,  2.4826e-02,\n","        -4.2086e-02,  2.6544e-02, -6.6952e-02, -4.7024e-02, -2.3067e-03,\n","        -3.1634e-03,  2.8113e-02,  8.3532e-03,  5.3238e-02,  1.4452e-01,\n","         9.9574e-03,  2.8608e-02,  5.6783e-02, -4.5777e-02,  1.2043e-02,\n","         7.9522e-02,  5.0379e-02,  1.5862e-02, -2.8535e-02, -7.5681e-02,\n","         2.0986e-02,  4.4630e-02, -2.7845e-03, -1.2249e-02,  2.5750e-02,\n","         1.2314e-01,  2.2124e-02, -6.4032e-03,  1.1918e-02, -7.8375e-02,\n","         1.4377e-02,  1.6687e-02,  8.6727e-02, -7.2219e-02,  3.8441e-02,\n","         6.1347e-02, -1.2738e-02, -9.0578e-02,  1.1516e-01,  1.2339e-01,\n","        -6.3438e-02, -8.4962e-02, -6.6384e-02,  3.9714e-03,  4.2210e-02,\n","        -2.5302e-02,  7.6416e-03, -1.1345e-02, -3.7439e-02, -1.4544e-02,\n","         2.8958e-02, -6.5781e-03,  2.4235e-02,  7.0720e-02, -7.2059e-02,\n","        -7.6364e-02, -4.8424e-02,  9.2916e-02,  3.3656e-03, -3.9972e-02,\n","         9.3317e-02,  6.9324e-02,  2.1629e-02,  3.8722e-03,  1.0148e-02,\n","        -6.8312e-04,  1.8011e-02,  3.0170e-03,  1.0591e-01,  8.0535e-02,\n","         2.8001e-02, -9.6220e-03,  7.3421e-02, -8.2236e-02,  9.7083e-02,\n","         6.1132e-02, -6.2137e-03,  8.2618e-03,  8.5488e-04, -4.0847e-02,\n","         6.6871e-02,  3.8725e-02,  6.4569e-02, -4.4786e-02,  2.5871e-02,\n","        -4.1578e-02,  6.5629e-02,  3.2913e-03,  9.4469e-02,  1.5510e-02,\n","        -6.0654e-02,  7.1183e-02,  1.0228e-01, -2.9731e-02, -4.4467e-02,\n","         1.2158e-01, -2.6641e-03, -4.4608e-02, -8.4201e-03,  5.8481e-02,\n","         1.5535e-02, -1.5900e-02,  1.2649e-02, -1.0885e-02,  3.2575e-02,\n","        -2.8827e-02, -2.1462e-02,  1.6674e-02,  3.2184e-02,  4.3740e-02,\n","        -3.0049e-02, -1.2140e-02,  6.0269e-03, -3.2287e-02,  1.0170e-02,\n","         2.1944e-02, -4.8372e-02, -1.3215e-02,  7.8963e-02,  1.3557e-03,\n","         5.7206e-02, -4.7552e-02,  6.0579e-02, -1.6758e-02, -5.2439e-02,\n","         3.1019e-02,  7.2132e-02,  9.0046e-02,  2.1156e-02,  1.1068e-02,\n","         6.6166e-02, -1.1838e-01, -1.6424e-01,  3.6638e-02, -8.8503e-02,\n","        -1.1677e-01,  1.7999e-02, -3.6798e-02,  6.9175e-02,  3.2624e-02,\n","        -4.5108e-03,  5.9693e-02, -2.1357e-02, -4.2471e-02,  6.4146e-02,\n","        -2.3036e-02, -2.7662e-02,  4.7625e-02, -3.8169e-03,  4.6532e-02,\n","         1.0261e-01,  2.2966e-02, -3.4080e-02,  7.1599e-03,  3.9511e-02,\n","        -5.0750e-03,  1.3758e-01,  1.0675e-01,  7.1325e-02, -2.2061e-02,\n","         7.6282e-03, -1.0129e-01, -4.4939e-03,  6.3020e-03, -1.0073e-02,\n","        -5.2258e-03, -1.2992e-02,  2.6006e-02, -1.1052e-02, -9.9750e-02,\n","        -2.4359e-03,  8.8123e-02, -1.4044e-02,  5.5441e-02, -1.3377e-01,\n","         8.1158e-02, -2.3885e-02,  5.8374e-02,  9.6139e-02,  1.4972e-01,\n","        -5.3324e-02,  3.1059e-02,  4.1765e-02, -3.7619e-04,  2.1611e-02,\n","         7.9087e-02, -7.4574e-04,  1.0047e-02, -4.4500e-02, -8.3846e-03,\n","         3.3120e-02,  5.2718e-03,  1.4806e-02,  1.4919e-03, -1.1185e-01,\n","        -1.3584e-01,  4.0835e-02, -1.7009e-02, -3.0293e-03,  2.6326e-02,\n","         8.3146e-02, -1.3066e-02,  2.3895e-02,  6.2788e-03,  3.8794e-02,\n","         3.9600e-02,  5.5895e-03, -3.5232e-02, -1.3201e-02,  2.0152e-02,\n","        -5.7506e-02, -8.8728e-03,  3.1002e-02, -1.8033e-02,  7.8029e-03,\n","        -6.2108e-02,  5.5118e-02,  1.2836e-02, -2.6462e-02, -1.0261e-01,\n","         9.7931e-02,  5.4550e-02,  1.1948e-02,  7.0189e-02,  3.5685e-03,\n","        -2.1474e-02,  7.8336e-02, -4.9981e-02,  2.3667e-02, -2.5260e-02,\n","         1.0227e-01,  8.0817e-02,  1.1924e-02,  9.8591e-02,  1.8487e-02,\n","         1.0686e-02, -3.9545e-02,  1.1853e-01, -1.1480e-01,  3.8015e-02,\n","        -1.2189e-02,  2.5299e-02,  2.9865e-02,  2.5341e-02, -4.7209e-02,\n","        -2.2068e-02,  6.8748e-03,  6.9297e-02,  1.5324e-02,  3.3967e-02,\n","         9.7318e-02,  6.7822e-02, -1.4889e-03, -9.0082e-02,  1.1709e-01,\n","         1.1970e-02,  2.6102e-03,  2.1417e-02,  2.9506e-02,  6.8099e-02,\n","         7.2747e-02,  1.3697e-02,  1.4968e-01,  3.7311e-02, -2.6749e-02,\n","         8.1557e-03, -9.6444e-02, -1.8694e-02, -7.1726e-02, -1.7738e-02,\n","         6.1137e-05,  7.0006e-02, -9.6269e-02, -6.5747e-02,  2.8924e-02,\n","         4.5776e-02,  1.0858e-01,  4.9303e-02, -5.5550e-02, -2.9652e-02,\n","        -2.9472e-02,  9.0420e-03,  9.6421e-02, -3.9439e-02,  2.1365e-02,\n","         1.3208e-02,  1.0835e-01,  1.1745e-01, -8.3025e-03,  8.5314e-02,\n","         1.3254e-01, -1.2362e-02, -3.6455e-03, -6.4007e-02,  1.3305e-02,\n","        -2.2176e-02,  9.2354e-02,  4.1005e-02,  1.4436e-02,  3.5685e-02,\n","        -1.6310e-02, -5.1228e-02, -4.2177e-02,  1.0803e-02,  6.5309e-02,\n","         1.3865e-03, -1.6469e-02, -3.2767e-02, -1.0703e-01,  2.0354e-02,\n","         9.3742e-03,  1.2848e-01,  3.6112e-02,  5.8695e-02,  6.5809e-02,\n","         4.3762e-02,  1.1870e-02,  3.9097e-02, -2.3184e-02,  1.8029e-02,\n","         8.8130e-02, -1.5746e-04, -2.7483e-02,  4.6433e-02,  9.6117e-02,\n","         1.1438e-01, -1.1953e-01, -3.7087e-02, -1.2441e-01,  2.3787e-02,\n","         5.3873e-02, -3.4844e-02, -6.1729e-02, -7.7120e-02, -9.3024e-02,\n","         8.9346e-02,  1.7274e-02, -1.7748e-02, -7.1025e-02,  5.4243e-02],\n","       device='cuda:0', requires_grad=True)"]},"metadata":{},"execution_count":37}],"source":["model.fc1.bias"]},{"cell_type":"markdown","metadata":{"hidden":true,"id":"oqraljgym6xZ"},"source":["Es posible sobreescribir una capa de la siguiente manera"]},{"cell_type":"code","execution_count":38,"metadata":{"ExecuteTime":{"end_time":"2020-08-15T12:22:11.391810Z","start_time":"2020-08-15T12:22:11.376809Z"},"hidden":true,"id":"xIwyV17em6xZ","executionInfo":{"status":"ok","timestamp":1708948593801,"user_tz":240,"elapsed":423,"user":{"displayName":"Miguel Angel Choque Garcia","userId":"17908264217194701994"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"8cfa6684-5ba6-429d-bea6-f08e6b329092"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["ModelCustom2(\n","  (fc1): Linear(in_features=784, out_features=1000, bias=True)\n","  (relu): ReLU()\n","  (fc2): Linear(in_features=100, out_features=1, bias=True)\n",")"]},"metadata":{},"execution_count":38}],"source":["model.fc2 = torch.nn.Linear(100, 1)\n","\n","model"]},{"cell_type":"markdown","metadata":{"hidden":true,"id":"eVLw3r9im6xZ"},"source":["Ahora, la capa final de nuestra red tiene solo una salida. Esta nueva capa ha sido inicializada de manera aleatoria, por lo que esta nueva red no nos va a servir de mucho. Sin embargo, podríamos volver a entrenar esta red en otro problema en el que solo necesitemos una salida aprovechando los pesos que ya hemos entrenado anteriormente con el dataset MNIST. Esto es la base del *transfer learning*, una técnica que utilizaremos muchísimo más adelante y la cual explicaremos en detalle.\n","\n","A continuación encontrarás varios trucos a la hora de crear redes neuronales a partir de otras que te pueden resultar útiles."]},{"cell_type":"code","execution_count":39,"metadata":{"ExecuteTime":{"end_time":"2020-08-15T12:22:11.406809Z","start_time":"2020-08-15T12:22:11.393812Z"},"hidden":true,"id":"JfE83wXtm6xZ","executionInfo":{"status":"ok","timestamp":1708948595568,"user_tz":240,"elapsed":356,"user":{"displayName":"Miguel Angel Choque Garcia","userId":"17908264217194701994"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"19d6ac4d-1056-4978-e2ac-719b0bf4f1bc"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["[Linear(in_features=784, out_features=1000, bias=True),\n"," ReLU(),\n"," Linear(in_features=100, out_features=1, bias=True)]"]},"metadata":{},"execution_count":39}],"source":["# obtener una lista con las capas de una red\n","\n","list(model.children())"]},{"cell_type":"code","execution_count":40,"metadata":{"ExecuteTime":{"end_time":"2020-08-15T12:22:11.422810Z","start_time":"2020-08-15T12:22:11.408810Z"},"hidden":true,"id":"wkaUklFHm6xa","executionInfo":{"status":"ok","timestamp":1708948596934,"user_tz":240,"elapsed":6,"user":{"displayName":"Miguel Angel Choque Garcia","userId":"17908264217194701994"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"b972c32c-3fb7-401d-ea4e-fae14c22c28b"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["Sequential(\n","  (0): Linear(in_features=784, out_features=1000, bias=True)\n",")"]},"metadata":{},"execution_count":40}],"source":["# crear nueva red a partir de la lista (excluyendo las útlimas dos capa)\n","\n","new_model = torch.nn.Sequential(*list(model.children())[:-2])\n","new_model"]},{"cell_type":"code","execution_count":41,"metadata":{"ExecuteTime":{"end_time":"2020-08-15T12:22:11.438809Z","start_time":"2020-08-15T12:22:11.424811Z"},"hidden":true,"id":"AcGFOSU5m6xa","executionInfo":{"status":"ok","timestamp":1708948598946,"user_tz":240,"elapsed":303,"user":{"displayName":"Miguel Angel Choque Garcia","userId":"17908264217194701994"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"65b7090c-bfad-49cd-96b6-65d0c0da0e57"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["ModuleList(\n","  (0): Linear(in_features=784, out_features=1000, bias=True)\n","  (1): ReLU()\n",")"]},"metadata":{},"execution_count":41}],"source":["# crear nueva red a partir de la lista (excluyendo las útlima capa)\n","\n","new_model = torch.nn.ModuleList(list(model.children())[:-1])\n","new_model"]},{"cell_type":"markdown","metadata":{"id":"2IanjDRkm6xa"},"source":["## Resumen"]},{"cell_type":"markdown","metadata":{"id":"PwR1F8c9m6xa"},"source":["En este post hemos visto la funcionalidad que `Pytorch` nos ofrece a la hora de definir y entrenar nuestras `redes neuronales`. El paquete `torch.nn` contiene todo lo necesario para diseñar nuestros modelos, ya sea de manera secuencial o con una clase *custom* para arquitecturas más complicadas. También nos da muchas funciones de pérdida que podemos usar directamente para entrenar las redes. Te recomiendo encarecidamente que le eches un vistazo a la [documentación](https://pytorch.org/docs/stable/nn.html) par hacerte una idea de todo lo que puedes hacer. También hemos visto como el paquete `torch.optim` nos oferece algoritmos de optimización que también nos hacen la vida más fácil a la hora de entrenar nuestras redes."]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.3"},"toc":{"base_numbering":1,"nav_menu":{},"number_sections":true,"sideBar":true,"skip_h1_title":false,"title_cell":"Table of Contents","title_sidebar":"Contents","toc_cell":false,"toc_position":{"height":"calc(100% - 180px)","left":"10px","top":"150px","width":"233.594px"},"toc_section_display":true,"toc_window_display":false},"colab":{"provenance":[{"file_id":"13fH9DryrWugCWCPINoSYW2sh4RNE9P9x","timestamp":1708944923800},{"file_id":"https://github.com/juansensio/blog/blob/master/028_pytorch_nn/pytorch_nn.ipynb","timestamp":1649227319930}]},"accelerator":"GPU","gpuClass":"standard"},"nbformat":4,"nbformat_minor":0}